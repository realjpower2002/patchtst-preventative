{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 11.0,
  "eval_steps": 500,
  "global_step": 28028,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.019623233908948195,
      "grad_norm": 0.30839964747428894,
      "learning_rate": 4.9903846153846154e-05,
      "loss": 0.6412,
      "step": 50
    },
    {
      "epoch": 0.03924646781789639,
      "grad_norm": 0.2794131934642792,
      "learning_rate": 4.9805729984301415e-05,
      "loss": 0.4855,
      "step": 100
    },
    {
      "epoch": 0.05886970172684458,
      "grad_norm": 2.256641149520874,
      "learning_rate": 4.9707613814756676e-05,
      "loss": 0.367,
      "step": 150
    },
    {
      "epoch": 0.07849293563579278,
      "grad_norm": 0.9094319343566895,
      "learning_rate": 4.960949764521193e-05,
      "loss": 0.2945,
      "step": 200
    },
    {
      "epoch": 0.09811616954474098,
      "grad_norm": 0.811332106590271,
      "learning_rate": 4.951138147566719e-05,
      "loss": 0.2667,
      "step": 250
    },
    {
      "epoch": 0.11773940345368916,
      "grad_norm": 0.7112467288970947,
      "learning_rate": 4.941326530612245e-05,
      "loss": 0.252,
      "step": 300
    },
    {
      "epoch": 0.13736263736263737,
      "grad_norm": 0.8579742908477783,
      "learning_rate": 4.931514913657771e-05,
      "loss": 0.2437,
      "step": 350
    },
    {
      "epoch": 0.15698587127158556,
      "grad_norm": 0.4823269248008728,
      "learning_rate": 4.9217032967032966e-05,
      "loss": 0.235,
      "step": 400
    },
    {
      "epoch": 0.17660910518053374,
      "grad_norm": 1.1497149467468262,
      "learning_rate": 4.911891679748823e-05,
      "loss": 0.2338,
      "step": 450
    },
    {
      "epoch": 0.19623233908948196,
      "grad_norm": 0.7090773582458496,
      "learning_rate": 4.902080062794349e-05,
      "loss": 0.2303,
      "step": 500
    },
    {
      "epoch": 0.21585557299843014,
      "grad_norm": 0.9524086117744446,
      "learning_rate": 4.892268445839875e-05,
      "loss": 0.2276,
      "step": 550
    },
    {
      "epoch": 0.23547880690737832,
      "grad_norm": 1.5349451303482056,
      "learning_rate": 4.8824568288854e-05,
      "loss": 0.2247,
      "step": 600
    },
    {
      "epoch": 0.25510204081632654,
      "grad_norm": 0.48404359817504883,
      "learning_rate": 4.872645211930926e-05,
      "loss": 0.2254,
      "step": 650
    },
    {
      "epoch": 0.27472527472527475,
      "grad_norm": 1.1404423713684082,
      "learning_rate": 4.8628335949764524e-05,
      "loss": 0.2249,
      "step": 700
    },
    {
      "epoch": 0.2943485086342229,
      "grad_norm": 1.353710651397705,
      "learning_rate": 4.8530219780219785e-05,
      "loss": 0.2217,
      "step": 750
    },
    {
      "epoch": 0.3139717425431711,
      "grad_norm": 0.567766547203064,
      "learning_rate": 4.843210361067504e-05,
      "loss": 0.2262,
      "step": 800
    },
    {
      "epoch": 0.33359497645211933,
      "grad_norm": 0.8271063566207886,
      "learning_rate": 4.83339874411303e-05,
      "loss": 0.2191,
      "step": 850
    },
    {
      "epoch": 0.3532182103610675,
      "grad_norm": 0.6242493391036987,
      "learning_rate": 4.823587127158556e-05,
      "loss": 0.2193,
      "step": 900
    },
    {
      "epoch": 0.3728414442700157,
      "grad_norm": 1.1799074411392212,
      "learning_rate": 4.813775510204082e-05,
      "loss": 0.2163,
      "step": 950
    },
    {
      "epoch": 0.3924646781789639,
      "grad_norm": 0.6452319025993347,
      "learning_rate": 4.8039638932496075e-05,
      "loss": 0.2166,
      "step": 1000
    },
    {
      "epoch": 0.41208791208791207,
      "grad_norm": 0.8252454996109009,
      "learning_rate": 4.7941522762951336e-05,
      "loss": 0.2166,
      "step": 1050
    },
    {
      "epoch": 0.4317111459968603,
      "grad_norm": 0.8099313378334045,
      "learning_rate": 4.78434065934066e-05,
      "loss": 0.213,
      "step": 1100
    },
    {
      "epoch": 0.4513343799058085,
      "grad_norm": 0.8590015769004822,
      "learning_rate": 4.774529042386186e-05,
      "loss": 0.2156,
      "step": 1150
    },
    {
      "epoch": 0.47095761381475665,
      "grad_norm": 0.7966881990432739,
      "learning_rate": 4.764717425431711e-05,
      "loss": 0.211,
      "step": 1200
    },
    {
      "epoch": 0.49058084772370486,
      "grad_norm": 0.5888208150863647,
      "learning_rate": 4.754905808477237e-05,
      "loss": 0.2124,
      "step": 1250
    },
    {
      "epoch": 0.5102040816326531,
      "grad_norm": 1.048002004623413,
      "learning_rate": 4.745094191522763e-05,
      "loss": 0.2113,
      "step": 1300
    },
    {
      "epoch": 0.5298273155416012,
      "grad_norm": 1.1078420877456665,
      "learning_rate": 4.735282574568289e-05,
      "loss": 0.2112,
      "step": 1350
    },
    {
      "epoch": 0.5494505494505495,
      "grad_norm": 0.7269852757453918,
      "learning_rate": 4.725470957613815e-05,
      "loss": 0.2121,
      "step": 1400
    },
    {
      "epoch": 0.5690737833594977,
      "grad_norm": 0.6617816686630249,
      "learning_rate": 4.715659340659341e-05,
      "loss": 0.2063,
      "step": 1450
    },
    {
      "epoch": 0.5886970172684458,
      "grad_norm": 0.9398244619369507,
      "learning_rate": 4.705847723704867e-05,
      "loss": 0.2082,
      "step": 1500
    },
    {
      "epoch": 0.6083202511773941,
      "grad_norm": 0.5138371586799622,
      "learning_rate": 4.696036106750393e-05,
      "loss": 0.2033,
      "step": 1550
    },
    {
      "epoch": 0.6279434850863422,
      "grad_norm": 1.1170330047607422,
      "learning_rate": 4.6862244897959184e-05,
      "loss": 0.203,
      "step": 1600
    },
    {
      "epoch": 0.6475667189952904,
      "grad_norm": 0.8364686965942383,
      "learning_rate": 4.6764128728414445e-05,
      "loss": 0.1998,
      "step": 1650
    },
    {
      "epoch": 0.6671899529042387,
      "grad_norm": 0.4572080373764038,
      "learning_rate": 4.6666012558869706e-05,
      "loss": 0.2011,
      "step": 1700
    },
    {
      "epoch": 0.6868131868131868,
      "grad_norm": 0.6296447515487671,
      "learning_rate": 4.656789638932496e-05,
      "loss": 0.1987,
      "step": 1750
    },
    {
      "epoch": 0.706436420722135,
      "grad_norm": 1.5071191787719727,
      "learning_rate": 4.646978021978022e-05,
      "loss": 0.1976,
      "step": 1800
    },
    {
      "epoch": 0.7260596546310832,
      "grad_norm": 1.3817378282546997,
      "learning_rate": 4.637166405023548e-05,
      "loss": 0.1973,
      "step": 1850
    },
    {
      "epoch": 0.7456828885400314,
      "grad_norm": 1.260256052017212,
      "learning_rate": 4.6273547880690735e-05,
      "loss": 0.1947,
      "step": 1900
    },
    {
      "epoch": 0.7653061224489796,
      "grad_norm": 1.3558027744293213,
      "learning_rate": 4.6175431711146e-05,
      "loss": 0.1944,
      "step": 1950
    },
    {
      "epoch": 0.7849293563579278,
      "grad_norm": 1.3628939390182495,
      "learning_rate": 4.607731554160126e-05,
      "loss": 0.1923,
      "step": 2000
    },
    {
      "epoch": 0.804552590266876,
      "grad_norm": 1.451006531715393,
      "learning_rate": 4.597919937205652e-05,
      "loss": 0.1889,
      "step": 2050
    },
    {
      "epoch": 0.8241758241758241,
      "grad_norm": 1.4819344282150269,
      "learning_rate": 4.588108320251178e-05,
      "loss": 0.1862,
      "step": 2100
    },
    {
      "epoch": 0.8437990580847724,
      "grad_norm": 1.1625503301620483,
      "learning_rate": 4.578296703296703e-05,
      "loss": 0.1858,
      "step": 2150
    },
    {
      "epoch": 0.8634222919937206,
      "grad_norm": 1.5611393451690674,
      "learning_rate": 4.568485086342229e-05,
      "loss": 0.1839,
      "step": 2200
    },
    {
      "epoch": 0.8830455259026687,
      "grad_norm": 1.2459888458251953,
      "learning_rate": 4.5586734693877554e-05,
      "loss": 0.1812,
      "step": 2250
    },
    {
      "epoch": 0.902668759811617,
      "grad_norm": 1.4682022333145142,
      "learning_rate": 4.548861852433281e-05,
      "loss": 0.1828,
      "step": 2300
    },
    {
      "epoch": 0.9222919937205651,
      "grad_norm": 1.8903566598892212,
      "learning_rate": 4.5390502354788075e-05,
      "loss": 0.1815,
      "step": 2350
    },
    {
      "epoch": 0.9419152276295133,
      "grad_norm": 2.0343968868255615,
      "learning_rate": 4.529238618524333e-05,
      "loss": 0.18,
      "step": 2400
    },
    {
      "epoch": 0.9615384615384616,
      "grad_norm": 3.104841947555542,
      "learning_rate": 4.519427001569858e-05,
      "loss": 0.1797,
      "step": 2450
    },
    {
      "epoch": 0.9811616954474097,
      "grad_norm": 0.941974401473999,
      "learning_rate": 4.509615384615385e-05,
      "loss": 0.1752,
      "step": 2500
    },
    {
      "epoch": 1.0,
      "eval_runtime": 30.9381,
      "eval_samples_per_second": 658.671,
      "eval_steps_per_second": 20.59,
      "step": 2548
    },
    {
      "epoch": 1.000784929356358,
      "grad_norm": 1.9551867246627808,
      "learning_rate": 4.4998037676609105e-05,
      "loss": 0.1783,
      "step": 2550
    },
    {
      "epoch": 1.0204081632653061,
      "grad_norm": 2.535970687866211,
      "learning_rate": 4.4899921507064366e-05,
      "loss": 0.1746,
      "step": 2600
    },
    {
      "epoch": 1.0400313971742543,
      "grad_norm": 5.567418098449707,
      "learning_rate": 4.4801805337519626e-05,
      "loss": 0.1728,
      "step": 2650
    },
    {
      "epoch": 1.0596546310832025,
      "grad_norm": 2.597290515899658,
      "learning_rate": 4.470368916797488e-05,
      "loss": 0.1694,
      "step": 2700
    },
    {
      "epoch": 1.0792778649921506,
      "grad_norm": 1.5226540565490723,
      "learning_rate": 4.460557299843015e-05,
      "loss": 0.1737,
      "step": 2750
    },
    {
      "epoch": 1.098901098901099,
      "grad_norm": 2.55260968208313,
      "learning_rate": 4.45074568288854e-05,
      "loss": 0.1695,
      "step": 2800
    },
    {
      "epoch": 1.1185243328100472,
      "grad_norm": 3.401707887649536,
      "learning_rate": 4.4409340659340656e-05,
      "loss": 0.1685,
      "step": 2850
    },
    {
      "epoch": 1.1381475667189953,
      "grad_norm": 2.816251039505005,
      "learning_rate": 4.4311224489795923e-05,
      "loss": 0.1708,
      "step": 2900
    },
    {
      "epoch": 1.1577708006279435,
      "grad_norm": 3.3615949153900146,
      "learning_rate": 4.421310832025118e-05,
      "loss": 0.1668,
      "step": 2950
    },
    {
      "epoch": 1.1773940345368916,
      "grad_norm": 2.1576547622680664,
      "learning_rate": 4.411499215070644e-05,
      "loss": 0.1666,
      "step": 3000
    },
    {
      "epoch": 1.19701726844584,
      "grad_norm": 1.5313994884490967,
      "learning_rate": 4.40168759811617e-05,
      "loss": 0.1653,
      "step": 3050
    },
    {
      "epoch": 1.2166405023547882,
      "grad_norm": 3.8457231521606445,
      "learning_rate": 4.391875981161695e-05,
      "loss": 0.1649,
      "step": 3100
    },
    {
      "epoch": 1.2362637362637363,
      "grad_norm": 1.9840260744094849,
      "learning_rate": 4.382064364207222e-05,
      "loss": 0.1622,
      "step": 3150
    },
    {
      "epoch": 1.2558869701726845,
      "grad_norm": 4.362919330596924,
      "learning_rate": 4.3722527472527474e-05,
      "loss": 0.1625,
      "step": 3200
    },
    {
      "epoch": 1.2755102040816326,
      "grad_norm": 3.335237741470337,
      "learning_rate": 4.362441130298273e-05,
      "loss": 0.1621,
      "step": 3250
    },
    {
      "epoch": 1.2951334379905808,
      "grad_norm": 5.26850700378418,
      "learning_rate": 4.3526295133437996e-05,
      "loss": 0.1624,
      "step": 3300
    },
    {
      "epoch": 1.314756671899529,
      "grad_norm": 4.735275745391846,
      "learning_rate": 4.342817896389325e-05,
      "loss": 0.1616,
      "step": 3350
    },
    {
      "epoch": 1.3343799058084773,
      "grad_norm": 2.325209140777588,
      "learning_rate": 4.333006279434851e-05,
      "loss": 0.1599,
      "step": 3400
    },
    {
      "epoch": 1.3540031397174255,
      "grad_norm": 3.258694887161255,
      "learning_rate": 4.323194662480377e-05,
      "loss": 0.1575,
      "step": 3450
    },
    {
      "epoch": 1.3736263736263736,
      "grad_norm": 3.6141488552093506,
      "learning_rate": 4.3133830455259026e-05,
      "loss": 0.1583,
      "step": 3500
    },
    {
      "epoch": 1.3932496075353218,
      "grad_norm": 3.8222134113311768,
      "learning_rate": 4.303571428571429e-05,
      "loss": 0.1561,
      "step": 3550
    },
    {
      "epoch": 1.41287284144427,
      "grad_norm": 3.1434764862060547,
      "learning_rate": 4.293759811616955e-05,
      "loss": 0.1575,
      "step": 3600
    },
    {
      "epoch": 1.4324960753532183,
      "grad_norm": 2.6277294158935547,
      "learning_rate": 4.28394819466248e-05,
      "loss": 0.156,
      "step": 3650
    },
    {
      "epoch": 1.4521193092621665,
      "grad_norm": 7.460547924041748,
      "learning_rate": 4.274136577708007e-05,
      "loss": 0.1559,
      "step": 3700
    },
    {
      "epoch": 1.4717425431711146,
      "grad_norm": 3.8251636028289795,
      "learning_rate": 4.264324960753532e-05,
      "loss": 0.1551,
      "step": 3750
    },
    {
      "epoch": 1.4913657770800628,
      "grad_norm": 5.55992317199707,
      "learning_rate": 4.254513343799058e-05,
      "loss": 0.1539,
      "step": 3800
    },
    {
      "epoch": 1.510989010989011,
      "grad_norm": 4.436182975769043,
      "learning_rate": 4.2447017268445844e-05,
      "loss": 0.1537,
      "step": 3850
    },
    {
      "epoch": 1.5306122448979593,
      "grad_norm": 5.019519329071045,
      "learning_rate": 4.23489010989011e-05,
      "loss": 0.1553,
      "step": 3900
    },
    {
      "epoch": 1.5502354788069073,
      "grad_norm": 4.0342936515808105,
      "learning_rate": 4.225078492935636e-05,
      "loss": 0.1524,
      "step": 3950
    },
    {
      "epoch": 1.5698587127158556,
      "grad_norm": 3.145026683807373,
      "learning_rate": 4.215266875981162e-05,
      "loss": 0.1512,
      "step": 4000
    },
    {
      "epoch": 1.5894819466248038,
      "grad_norm": 8.127691268920898,
      "learning_rate": 4.2054552590266874e-05,
      "loss": 0.1486,
      "step": 4050
    },
    {
      "epoch": 1.609105180533752,
      "grad_norm": 4.4838385581970215,
      "learning_rate": 4.195643642072214e-05,
      "loss": 0.1519,
      "step": 4100
    },
    {
      "epoch": 1.6287284144427001,
      "grad_norm": 4.023062705993652,
      "learning_rate": 4.1858320251177395e-05,
      "loss": 0.1501,
      "step": 4150
    },
    {
      "epoch": 1.6483516483516483,
      "grad_norm": 2.3843178749084473,
      "learning_rate": 4.1760204081632656e-05,
      "loss": 0.1463,
      "step": 4200
    },
    {
      "epoch": 1.6679748822605966,
      "grad_norm": 5.4677205085754395,
      "learning_rate": 4.166208791208792e-05,
      "loss": 0.1486,
      "step": 4250
    },
    {
      "epoch": 1.6875981161695446,
      "grad_norm": 3.162881851196289,
      "learning_rate": 4.156397174254317e-05,
      "loss": 0.1471,
      "step": 4300
    },
    {
      "epoch": 1.707221350078493,
      "grad_norm": 4.266803741455078,
      "learning_rate": 4.146585557299843e-05,
      "loss": 0.1486,
      "step": 4350
    },
    {
      "epoch": 1.7268445839874411,
      "grad_norm": 3.9153130054473877,
      "learning_rate": 4.136773940345369e-05,
      "loss": 0.148,
      "step": 4400
    },
    {
      "epoch": 1.7464678178963893,
      "grad_norm": 4.988833427429199,
      "learning_rate": 4.1269623233908946e-05,
      "loss": 0.1453,
      "step": 4450
    },
    {
      "epoch": 1.7660910518053377,
      "grad_norm": 4.468367099761963,
      "learning_rate": 4.117150706436421e-05,
      "loss": 0.1433,
      "step": 4500
    },
    {
      "epoch": 1.7857142857142856,
      "grad_norm": 3.586076021194458,
      "learning_rate": 4.107339089481947e-05,
      "loss": 0.1447,
      "step": 4550
    },
    {
      "epoch": 1.805337519623234,
      "grad_norm": 6.366526126861572,
      "learning_rate": 4.097527472527473e-05,
      "loss": 0.1417,
      "step": 4600
    },
    {
      "epoch": 1.8249607535321821,
      "grad_norm": 3.3398170471191406,
      "learning_rate": 4.087715855572999e-05,
      "loss": 0.143,
      "step": 4650
    },
    {
      "epoch": 1.8445839874411303,
      "grad_norm": 4.038153648376465,
      "learning_rate": 4.077904238618524e-05,
      "loss": 0.1394,
      "step": 4700
    },
    {
      "epoch": 1.8642072213500787,
      "grad_norm": 6.498599052429199,
      "learning_rate": 4.0680926216640504e-05,
      "loss": 0.1384,
      "step": 4750
    },
    {
      "epoch": 1.8838304552590266,
      "grad_norm": 6.430575847625732,
      "learning_rate": 4.0582810047095765e-05,
      "loss": 0.1387,
      "step": 4800
    },
    {
      "epoch": 1.903453689167975,
      "grad_norm": 5.406408786773682,
      "learning_rate": 4.048469387755102e-05,
      "loss": 0.1398,
      "step": 4850
    },
    {
      "epoch": 1.9230769230769231,
      "grad_norm": 4.788869380950928,
      "learning_rate": 4.038657770800628e-05,
      "loss": 0.1382,
      "step": 4900
    },
    {
      "epoch": 1.9427001569858713,
      "grad_norm": 4.118043422698975,
      "learning_rate": 4.028846153846154e-05,
      "loss": 0.1352,
      "step": 4950
    },
    {
      "epoch": 1.9623233908948194,
      "grad_norm": 3.4045255184173584,
      "learning_rate": 4.01903453689168e-05,
      "loss": 0.136,
      "step": 5000
    },
    {
      "epoch": 1.9819466248037676,
      "grad_norm": 5.152231693267822,
      "learning_rate": 4.009222919937206e-05,
      "loss": 0.1373,
      "step": 5050
    },
    {
      "epoch": 2.0,
      "eval_runtime": 30.9507,
      "eval_samples_per_second": 658.401,
      "eval_steps_per_second": 20.581,
      "step": 5096
    },
    {
      "epoch": 2.001569858712716,
      "grad_norm": 5.24843692779541,
      "learning_rate": 3.9994113029827316e-05,
      "loss": 0.135,
      "step": 5100
    },
    {
      "epoch": 2.021193092621664,
      "grad_norm": 10.583897590637207,
      "learning_rate": 3.989599686028258e-05,
      "loss": 0.1351,
      "step": 5150
    },
    {
      "epoch": 2.0408163265306123,
      "grad_norm": 7.026779651641846,
      "learning_rate": 3.979788069073784e-05,
      "loss": 0.1354,
      "step": 5200
    },
    {
      "epoch": 2.0604395604395602,
      "grad_norm": 4.627380847930908,
      "learning_rate": 3.969976452119309e-05,
      "loss": 0.1344,
      "step": 5250
    },
    {
      "epoch": 2.0800627943485086,
      "grad_norm": 6.87925386428833,
      "learning_rate": 3.960164835164835e-05,
      "loss": 0.1321,
      "step": 5300
    },
    {
      "epoch": 2.099686028257457,
      "grad_norm": 4.7671332359313965,
      "learning_rate": 3.950353218210361e-05,
      "loss": 0.131,
      "step": 5350
    },
    {
      "epoch": 2.119309262166405,
      "grad_norm": 4.461031436920166,
      "learning_rate": 3.9405416012558874e-05,
      "loss": 0.1315,
      "step": 5400
    },
    {
      "epoch": 2.1389324960753533,
      "grad_norm": 4.2860026359558105,
      "learning_rate": 3.930729984301413e-05,
      "loss": 0.1298,
      "step": 5450
    },
    {
      "epoch": 2.1585557299843012,
      "grad_norm": 4.892852306365967,
      "learning_rate": 3.920918367346939e-05,
      "loss": 0.1303,
      "step": 5500
    },
    {
      "epoch": 2.1781789638932496,
      "grad_norm": 5.251241207122803,
      "learning_rate": 3.911106750392465e-05,
      "loss": 0.128,
      "step": 5550
    },
    {
      "epoch": 2.197802197802198,
      "grad_norm": 7.290555477142334,
      "learning_rate": 3.901295133437991e-05,
      "loss": 0.1279,
      "step": 5600
    },
    {
      "epoch": 2.217425431711146,
      "grad_norm": 6.009480953216553,
      "learning_rate": 3.8914835164835164e-05,
      "loss": 0.1275,
      "step": 5650
    },
    {
      "epoch": 2.2370486656200943,
      "grad_norm": 4.315043926239014,
      "learning_rate": 3.8816718995290425e-05,
      "loss": 0.1262,
      "step": 5700
    },
    {
      "epoch": 2.2566718995290422,
      "grad_norm": 7.937936305999756,
      "learning_rate": 3.8718602825745686e-05,
      "loss": 0.1251,
      "step": 5750
    },
    {
      "epoch": 2.2762951334379906,
      "grad_norm": 6.768514156341553,
      "learning_rate": 3.8620486656200946e-05,
      "loss": 0.1243,
      "step": 5800
    },
    {
      "epoch": 2.295918367346939,
      "grad_norm": 5.517353534698486,
      "learning_rate": 3.85223704866562e-05,
      "loss": 0.1255,
      "step": 5850
    },
    {
      "epoch": 2.315541601255887,
      "grad_norm": 8.640660285949707,
      "learning_rate": 3.842425431711146e-05,
      "loss": 0.1235,
      "step": 5900
    },
    {
      "epoch": 2.3351648351648353,
      "grad_norm": 10.062443733215332,
      "learning_rate": 3.832613814756672e-05,
      "loss": 0.1225,
      "step": 5950
    },
    {
      "epoch": 2.3547880690737832,
      "grad_norm": 8.012399673461914,
      "learning_rate": 3.8228021978021976e-05,
      "loss": 0.1232,
      "step": 6000
    },
    {
      "epoch": 2.3744113029827316,
      "grad_norm": 6.451811790466309,
      "learning_rate": 3.812990580847724e-05,
      "loss": 0.1233,
      "step": 6050
    },
    {
      "epoch": 2.39403453689168,
      "grad_norm": 8.2503662109375,
      "learning_rate": 3.80317896389325e-05,
      "loss": 0.1211,
      "step": 6100
    },
    {
      "epoch": 2.413657770800628,
      "grad_norm": 8.003379821777344,
      "learning_rate": 3.793367346938776e-05,
      "loss": 0.1209,
      "step": 6150
    },
    {
      "epoch": 2.4332810047095763,
      "grad_norm": 8.241719245910645,
      "learning_rate": 3.783555729984302e-05,
      "loss": 0.1203,
      "step": 6200
    },
    {
      "epoch": 2.4529042386185242,
      "grad_norm": 5.825170516967773,
      "learning_rate": 3.773744113029827e-05,
      "loss": 0.1175,
      "step": 6250
    },
    {
      "epoch": 2.4725274725274726,
      "grad_norm": 7.287900447845459,
      "learning_rate": 3.7639324960753534e-05,
      "loss": 0.117,
      "step": 6300
    },
    {
      "epoch": 2.4921507064364206,
      "grad_norm": 12.28135871887207,
      "learning_rate": 3.7541208791208795e-05,
      "loss": 0.1178,
      "step": 6350
    },
    {
      "epoch": 2.511773940345369,
      "grad_norm": 5.314082145690918,
      "learning_rate": 3.744309262166405e-05,
      "loss": 0.1166,
      "step": 6400
    },
    {
      "epoch": 2.531397174254317,
      "grad_norm": 10.509502410888672,
      "learning_rate": 3.734497645211931e-05,
      "loss": 0.1162,
      "step": 6450
    },
    {
      "epoch": 2.5510204081632653,
      "grad_norm": 6.4175286293029785,
      "learning_rate": 3.724686028257457e-05,
      "loss": 0.117,
      "step": 6500
    },
    {
      "epoch": 2.5706436420722136,
      "grad_norm": 11.009688377380371,
      "learning_rate": 3.7148744113029824e-05,
      "loss": 0.1153,
      "step": 6550
    },
    {
      "epoch": 2.5902668759811616,
      "grad_norm": 7.71728515625,
      "learning_rate": 3.705062794348509e-05,
      "loss": 0.1149,
      "step": 6600
    },
    {
      "epoch": 2.60989010989011,
      "grad_norm": 7.036815166473389,
      "learning_rate": 3.6952511773940346e-05,
      "loss": 0.113,
      "step": 6650
    },
    {
      "epoch": 2.629513343799058,
      "grad_norm": 7.102169036865234,
      "learning_rate": 3.6854395604395606e-05,
      "loss": 0.1134,
      "step": 6700
    },
    {
      "epoch": 2.6491365777080063,
      "grad_norm": 10.106293678283691,
      "learning_rate": 3.675627943485087e-05,
      "loss": 0.1133,
      "step": 6750
    },
    {
      "epoch": 2.6687598116169546,
      "grad_norm": 9.059621810913086,
      "learning_rate": 3.665816326530612e-05,
      "loss": 0.115,
      "step": 6800
    },
    {
      "epoch": 2.6883830455259026,
      "grad_norm": 6.504884719848633,
      "learning_rate": 3.656004709576138e-05,
      "loss": 0.1114,
      "step": 6850
    },
    {
      "epoch": 2.708006279434851,
      "grad_norm": 9.242345809936523,
      "learning_rate": 3.646193092621664e-05,
      "loss": 0.1089,
      "step": 6900
    },
    {
      "epoch": 2.727629513343799,
      "grad_norm": 8.360006332397461,
      "learning_rate": 3.63638147566719e-05,
      "loss": 0.1081,
      "step": 6950
    },
    {
      "epoch": 2.7472527472527473,
      "grad_norm": 7.9952497482299805,
      "learning_rate": 3.6265698587127164e-05,
      "loss": 0.1089,
      "step": 7000
    },
    {
      "epoch": 2.7668759811616956,
      "grad_norm": 6.3047332763671875,
      "learning_rate": 3.616758241758242e-05,
      "loss": 0.107,
      "step": 7050
    },
    {
      "epoch": 2.7864992150706436,
      "grad_norm": 6.4540910720825195,
      "learning_rate": 3.606946624803768e-05,
      "loss": 0.1058,
      "step": 7100
    },
    {
      "epoch": 2.806122448979592,
      "grad_norm": 4.864527225494385,
      "learning_rate": 3.597135007849294e-05,
      "loss": 0.1066,
      "step": 7150
    },
    {
      "epoch": 2.82574568288854,
      "grad_norm": 5.586203098297119,
      "learning_rate": 3.5873233908948194e-05,
      "loss": 0.1049,
      "step": 7200
    },
    {
      "epoch": 2.8453689167974883,
      "grad_norm": 7.808341026306152,
      "learning_rate": 3.5775117739403454e-05,
      "loss": 0.1048,
      "step": 7250
    },
    {
      "epoch": 2.8649921507064366,
      "grad_norm": 7.17248010635376,
      "learning_rate": 3.5677001569858715e-05,
      "loss": 0.1029,
      "step": 7300
    },
    {
      "epoch": 2.8846153846153846,
      "grad_norm": 5.62786340713501,
      "learning_rate": 3.557888540031397e-05,
      "loss": 0.1037,
      "step": 7350
    },
    {
      "epoch": 2.904238618524333,
      "grad_norm": 8.430312156677246,
      "learning_rate": 3.548076923076924e-05,
      "loss": 0.1027,
      "step": 7400
    },
    {
      "epoch": 2.923861852433281,
      "grad_norm": 5.463134288787842,
      "learning_rate": 3.538265306122449e-05,
      "loss": 0.1006,
      "step": 7450
    },
    {
      "epoch": 2.9434850863422293,
      "grad_norm": 7.285257816314697,
      "learning_rate": 3.5284536891679745e-05,
      "loss": 0.1015,
      "step": 7500
    },
    {
      "epoch": 2.9631083202511777,
      "grad_norm": 5.603079795837402,
      "learning_rate": 3.518642072213501e-05,
      "loss": 0.0992,
      "step": 7550
    },
    {
      "epoch": 2.9827315541601256,
      "grad_norm": 13.71962833404541,
      "learning_rate": 3.5088304552590266e-05,
      "loss": 0.1008,
      "step": 7600
    },
    {
      "epoch": 3.0,
      "eval_runtime": 31.0165,
      "eval_samples_per_second": 657.005,
      "eval_steps_per_second": 20.537,
      "step": 7644
    },
    {
      "epoch": 3.002354788069074,
      "grad_norm": 6.921548366546631,
      "learning_rate": 3.499018838304553e-05,
      "loss": 0.0992,
      "step": 7650
    },
    {
      "epoch": 3.021978021978022,
      "grad_norm": 8.791261672973633,
      "learning_rate": 3.489207221350079e-05,
      "loss": 0.0994,
      "step": 7700
    },
    {
      "epoch": 3.0416012558869703,
      "grad_norm": 8.552593231201172,
      "learning_rate": 3.479395604395604e-05,
      "loss": 0.1006,
      "step": 7750
    },
    {
      "epoch": 3.061224489795918,
      "grad_norm": 7.836613655090332,
      "learning_rate": 3.469583987441131e-05,
      "loss": 0.0968,
      "step": 7800
    },
    {
      "epoch": 3.0808477237048666,
      "grad_norm": 9.302218437194824,
      "learning_rate": 3.459772370486656e-05,
      "loss": 0.0956,
      "step": 7850
    },
    {
      "epoch": 3.100470957613815,
      "grad_norm": 10.094538688659668,
      "learning_rate": 3.449960753532182e-05,
      "loss": 0.0952,
      "step": 7900
    },
    {
      "epoch": 3.120094191522763,
      "grad_norm": 6.398170471191406,
      "learning_rate": 3.4401491365777085e-05,
      "loss": 0.0949,
      "step": 7950
    },
    {
      "epoch": 3.1397174254317113,
      "grad_norm": 7.240074634552002,
      "learning_rate": 3.430337519623234e-05,
      "loss": 0.0946,
      "step": 8000
    },
    {
      "epoch": 3.159340659340659,
      "grad_norm": 9.95543384552002,
      "learning_rate": 3.42052590266876e-05,
      "loss": 0.0947,
      "step": 8050
    },
    {
      "epoch": 3.1789638932496076,
      "grad_norm": 8.554767608642578,
      "learning_rate": 3.410714285714286e-05,
      "loss": 0.0937,
      "step": 8100
    },
    {
      "epoch": 3.1985871271585555,
      "grad_norm": 5.459001064300537,
      "learning_rate": 3.4009026687598114e-05,
      "loss": 0.0927,
      "step": 8150
    },
    {
      "epoch": 3.218210361067504,
      "grad_norm": 6.267177104949951,
      "learning_rate": 3.391091051805338e-05,
      "loss": 0.0913,
      "step": 8200
    },
    {
      "epoch": 3.2378335949764523,
      "grad_norm": 5.727255821228027,
      "learning_rate": 3.3812794348508636e-05,
      "loss": 0.0922,
      "step": 8250
    },
    {
      "epoch": 3.2574568288854002,
      "grad_norm": 4.742421627044678,
      "learning_rate": 3.371467817896389e-05,
      "loss": 0.0906,
      "step": 8300
    },
    {
      "epoch": 3.2770800627943486,
      "grad_norm": 14.019889831542969,
      "learning_rate": 3.361656200941916e-05,
      "loss": 0.0906,
      "step": 8350
    },
    {
      "epoch": 3.2967032967032965,
      "grad_norm": 6.038660049438477,
      "learning_rate": 3.351844583987441e-05,
      "loss": 0.0883,
      "step": 8400
    },
    {
      "epoch": 3.316326530612245,
      "grad_norm": 5.542603969573975,
      "learning_rate": 3.342032967032967e-05,
      "loss": 0.0899,
      "step": 8450
    },
    {
      "epoch": 3.3359497645211933,
      "grad_norm": 8.98852252960205,
      "learning_rate": 3.332221350078493e-05,
      "loss": 0.0874,
      "step": 8500
    },
    {
      "epoch": 3.3555729984301412,
      "grad_norm": 7.348928928375244,
      "learning_rate": 3.322409733124019e-05,
      "loss": 0.0873,
      "step": 8550
    },
    {
      "epoch": 3.3751962323390896,
      "grad_norm": 5.468349456787109,
      "learning_rate": 3.312598116169545e-05,
      "loss": 0.0873,
      "step": 8600
    },
    {
      "epoch": 3.3948194662480375,
      "grad_norm": 7.482723236083984,
      "learning_rate": 3.302786499215071e-05,
      "loss": 0.0877,
      "step": 8650
    },
    {
      "epoch": 3.414442700156986,
      "grad_norm": 6.994419574737549,
      "learning_rate": 3.292974882260596e-05,
      "loss": 0.0874,
      "step": 8700
    },
    {
      "epoch": 3.4340659340659343,
      "grad_norm": 8.871810913085938,
      "learning_rate": 3.283163265306123e-05,
      "loss": 0.0858,
      "step": 8750
    },
    {
      "epoch": 3.4536891679748822,
      "grad_norm": 9.202069282531738,
      "learning_rate": 3.2733516483516484e-05,
      "loss": 0.085,
      "step": 8800
    },
    {
      "epoch": 3.4733124018838306,
      "grad_norm": 7.2004852294921875,
      "learning_rate": 3.2635400313971745e-05,
      "loss": 0.0841,
      "step": 8850
    },
    {
      "epoch": 3.4929356357927785,
      "grad_norm": 11.843266487121582,
      "learning_rate": 3.2537284144427006e-05,
      "loss": 0.0829,
      "step": 8900
    },
    {
      "epoch": 3.512558869701727,
      "grad_norm": 11.896032333374023,
      "learning_rate": 3.243916797488226e-05,
      "loss": 0.0848,
      "step": 8950
    },
    {
      "epoch": 3.5321821036106753,
      "grad_norm": 6.1915693283081055,
      "learning_rate": 3.234105180533752e-05,
      "loss": 0.0827,
      "step": 9000
    },
    {
      "epoch": 3.5518053375196232,
      "grad_norm": 7.530060768127441,
      "learning_rate": 3.224293563579278e-05,
      "loss": 0.082,
      "step": 9050
    },
    {
      "epoch": 3.571428571428571,
      "grad_norm": 4.787998199462891,
      "learning_rate": 3.2144819466248035e-05,
      "loss": 0.0805,
      "step": 9100
    },
    {
      "epoch": 3.5910518053375196,
      "grad_norm": 7.274084568023682,
      "learning_rate": 3.20467032967033e-05,
      "loss": 0.0793,
      "step": 9150
    },
    {
      "epoch": 3.610675039246468,
      "grad_norm": 5.816441535949707,
      "learning_rate": 3.194858712715856e-05,
      "loss": 0.0793,
      "step": 9200
    },
    {
      "epoch": 3.630298273155416,
      "grad_norm": 7.563442230224609,
      "learning_rate": 3.185047095761382e-05,
      "loss": 0.079,
      "step": 9250
    },
    {
      "epoch": 3.6499215070643642,
      "grad_norm": 5.430724620819092,
      "learning_rate": 3.175235478806908e-05,
      "loss": 0.0797,
      "step": 9300
    },
    {
      "epoch": 3.669544740973312,
      "grad_norm": 8.009976387023926,
      "learning_rate": 3.165423861852433e-05,
      "loss": 0.0797,
      "step": 9350
    },
    {
      "epoch": 3.6891679748822606,
      "grad_norm": 7.068727493286133,
      "learning_rate": 3.155612244897959e-05,
      "loss": 0.0791,
      "step": 9400
    },
    {
      "epoch": 3.708791208791209,
      "grad_norm": 6.661923885345459,
      "learning_rate": 3.1458006279434854e-05,
      "loss": 0.0789,
      "step": 9450
    },
    {
      "epoch": 3.728414442700157,
      "grad_norm": 6.729067802429199,
      "learning_rate": 3.135989010989011e-05,
      "loss": 0.0785,
      "step": 9500
    },
    {
      "epoch": 3.7480376766091053,
      "grad_norm": 9.149992942810059,
      "learning_rate": 3.126177394034537e-05,
      "loss": 0.0766,
      "step": 9550
    },
    {
      "epoch": 3.767660910518053,
      "grad_norm": 5.041068077087402,
      "learning_rate": 3.116365777080063e-05,
      "loss": 0.0758,
      "step": 9600
    },
    {
      "epoch": 3.7872841444270016,
      "grad_norm": 5.047417163848877,
      "learning_rate": 3.106554160125589e-05,
      "loss": 0.074,
      "step": 9650
    },
    {
      "epoch": 3.80690737833595,
      "grad_norm": 9.052533149719238,
      "learning_rate": 3.096742543171115e-05,
      "loss": 0.0754,
      "step": 9700
    },
    {
      "epoch": 3.826530612244898,
      "grad_norm": 5.728124618530273,
      "learning_rate": 3.0869309262166405e-05,
      "loss": 0.0741,
      "step": 9750
    },
    {
      "epoch": 3.8461538461538463,
      "grad_norm": 7.712183475494385,
      "learning_rate": 3.0771193092621666e-05,
      "loss": 0.0736,
      "step": 9800
    },
    {
      "epoch": 3.865777080062794,
      "grad_norm": 8.277166366577148,
      "learning_rate": 3.0673076923076926e-05,
      "loss": 0.0727,
      "step": 9850
    },
    {
      "epoch": 3.8854003139717426,
      "grad_norm": 5.651069164276123,
      "learning_rate": 3.057496075353218e-05,
      "loss": 0.0731,
      "step": 9900
    },
    {
      "epoch": 3.905023547880691,
      "grad_norm": 4.8166608810424805,
      "learning_rate": 3.047684458398744e-05,
      "loss": 0.0724,
      "step": 9950
    },
    {
      "epoch": 3.924646781789639,
      "grad_norm": 6.633097171783447,
      "learning_rate": 3.0378728414442702e-05,
      "loss": 0.0721,
      "step": 10000
    },
    {
      "epoch": 3.9442700156985873,
      "grad_norm": 5.017385005950928,
      "learning_rate": 3.028061224489796e-05,
      "loss": 0.073,
      "step": 10050
    },
    {
      "epoch": 3.963893249607535,
      "grad_norm": 4.753954887390137,
      "learning_rate": 3.0182496075353217e-05,
      "loss": 0.0715,
      "step": 10100
    },
    {
      "epoch": 3.9835164835164836,
      "grad_norm": 7.486789703369141,
      "learning_rate": 3.008437990580848e-05,
      "loss": 0.0728,
      "step": 10150
    },
    {
      "epoch": 4.0,
      "eval_runtime": 100.4001,
      "eval_samples_per_second": 202.968,
      "eval_steps_per_second": 6.345,
      "step": 10192
    },
    {
      "epoch": 4.003139717425432,
      "grad_norm": 9.354472160339355,
      "learning_rate": 2.9986263736263738e-05,
      "loss": 0.0718,
      "step": 10200
    },
    {
      "epoch": 4.02276295133438,
      "grad_norm": 7.431554794311523,
      "learning_rate": 2.9888147566719e-05,
      "loss": 0.0701,
      "step": 10250
    },
    {
      "epoch": 4.042386185243328,
      "grad_norm": 6.0573811531066895,
      "learning_rate": 2.9790031397174256e-05,
      "loss": 0.0709,
      "step": 10300
    },
    {
      "epoch": 4.062009419152276,
      "grad_norm": 10.386943817138672,
      "learning_rate": 2.9691915227629514e-05,
      "loss": 0.0717,
      "step": 10350
    },
    {
      "epoch": 4.081632653061225,
      "grad_norm": 4.4404802322387695,
      "learning_rate": 2.9593799058084775e-05,
      "loss": 0.0696,
      "step": 10400
    },
    {
      "epoch": 4.101255886970173,
      "grad_norm": 5.405828952789307,
      "learning_rate": 2.9495682888540032e-05,
      "loss": 0.0705,
      "step": 10450
    },
    {
      "epoch": 4.1208791208791204,
      "grad_norm": 8.042160034179688,
      "learning_rate": 2.939756671899529e-05,
      "loss": 0.0692,
      "step": 10500
    },
    {
      "epoch": 4.140502354788069,
      "grad_norm": 6.50607967376709,
      "learning_rate": 2.9299450549450553e-05,
      "loss": 0.068,
      "step": 10550
    },
    {
      "epoch": 4.160125588697017,
      "grad_norm": 8.183815002441406,
      "learning_rate": 2.920133437990581e-05,
      "loss": 0.0684,
      "step": 10600
    },
    {
      "epoch": 4.179748822605966,
      "grad_norm": 5.577093124389648,
      "learning_rate": 2.9103218210361065e-05,
      "loss": 0.068,
      "step": 10650
    },
    {
      "epoch": 4.199372056514914,
      "grad_norm": 6.24161434173584,
      "learning_rate": 2.900510204081633e-05,
      "loss": 0.0673,
      "step": 10700
    },
    {
      "epoch": 4.2189952904238615,
      "grad_norm": 4.584085464477539,
      "learning_rate": 2.8906985871271586e-05,
      "loss": 0.0678,
      "step": 10750
    },
    {
      "epoch": 4.23861852433281,
      "grad_norm": 6.1961588859558105,
      "learning_rate": 2.8808869701726847e-05,
      "loss": 0.0681,
      "step": 10800
    },
    {
      "epoch": 4.258241758241758,
      "grad_norm": 6.66663122177124,
      "learning_rate": 2.8710753532182104e-05,
      "loss": 0.0668,
      "step": 10850
    },
    {
      "epoch": 4.277864992150707,
      "grad_norm": 3.6457889080047607,
      "learning_rate": 2.8612637362637362e-05,
      "loss": 0.0665,
      "step": 10900
    },
    {
      "epoch": 4.297488226059655,
      "grad_norm": 5.326696395874023,
      "learning_rate": 2.8514521193092626e-05,
      "loss": 0.0664,
      "step": 10950
    },
    {
      "epoch": 4.3171114599686025,
      "grad_norm": 4.7859368324279785,
      "learning_rate": 2.8416405023547883e-05,
      "loss": 0.0645,
      "step": 11000
    },
    {
      "epoch": 4.336734693877551,
      "grad_norm": 6.098467826843262,
      "learning_rate": 2.8318288854003137e-05,
      "loss": 0.0668,
      "step": 11050
    },
    {
      "epoch": 4.356357927786499,
      "grad_norm": 6.6675543785095215,
      "learning_rate": 2.82201726844584e-05,
      "loss": 0.0652,
      "step": 11100
    },
    {
      "epoch": 4.375981161695448,
      "grad_norm": 3.6562142372131348,
      "learning_rate": 2.812205651491366e-05,
      "loss": 0.0659,
      "step": 11150
    },
    {
      "epoch": 4.395604395604396,
      "grad_norm": 9.51551628112793,
      "learning_rate": 2.802394034536892e-05,
      "loss": 0.0656,
      "step": 11200
    },
    {
      "epoch": 4.4152276295133435,
      "grad_norm": 5.202648639678955,
      "learning_rate": 2.7925824175824177e-05,
      "loss": 0.0655,
      "step": 11250
    },
    {
      "epoch": 4.434850863422292,
      "grad_norm": 3.8730170726776123,
      "learning_rate": 2.7827708006279434e-05,
      "loss": 0.0648,
      "step": 11300
    },
    {
      "epoch": 4.45447409733124,
      "grad_norm": 8.064438819885254,
      "learning_rate": 2.77295918367347e-05,
      "loss": 0.0641,
      "step": 11350
    },
    {
      "epoch": 4.474097331240189,
      "grad_norm": 5.000357151031494,
      "learning_rate": 2.7631475667189956e-05,
      "loss": 0.0633,
      "step": 11400
    },
    {
      "epoch": 4.493720565149137,
      "grad_norm": 5.4725751876831055,
      "learning_rate": 2.753335949764521e-05,
      "loss": 0.0641,
      "step": 11450
    },
    {
      "epoch": 4.5133437990580845,
      "grad_norm": 4.604809761047363,
      "learning_rate": 2.7435243328100474e-05,
      "loss": 0.0633,
      "step": 11500
    },
    {
      "epoch": 4.532967032967033,
      "grad_norm": 5.555224418640137,
      "learning_rate": 2.733712715855573e-05,
      "loss": 0.0634,
      "step": 11550
    },
    {
      "epoch": 4.552590266875981,
      "grad_norm": 4.158265113830566,
      "learning_rate": 2.723901098901099e-05,
      "loss": 0.0629,
      "step": 11600
    },
    {
      "epoch": 4.57221350078493,
      "grad_norm": 6.606040000915527,
      "learning_rate": 2.714089481946625e-05,
      "loss": 0.0627,
      "step": 11650
    },
    {
      "epoch": 4.591836734693878,
      "grad_norm": 10.44658374786377,
      "learning_rate": 2.7042778649921507e-05,
      "loss": 0.0624,
      "step": 11700
    },
    {
      "epoch": 4.6114599686028255,
      "grad_norm": 7.970032215118408,
      "learning_rate": 2.694466248037677e-05,
      "loss": 0.0632,
      "step": 11750
    },
    {
      "epoch": 4.631083202511774,
      "grad_norm": 4.5683698654174805,
      "learning_rate": 2.684654631083203e-05,
      "loss": 0.062,
      "step": 11800
    },
    {
      "epoch": 4.650706436420722,
      "grad_norm": 5.3349127769470215,
      "learning_rate": 2.6748430141287283e-05,
      "loss": 0.0622,
      "step": 11850
    },
    {
      "epoch": 4.670329670329671,
      "grad_norm": 9.577532768249512,
      "learning_rate": 2.6650313971742547e-05,
      "loss": 0.0615,
      "step": 11900
    },
    {
      "epoch": 4.689952904238618,
      "grad_norm": 10.660954475402832,
      "learning_rate": 2.6552197802197804e-05,
      "loss": 0.0624,
      "step": 11950
    },
    {
      "epoch": 4.7095761381475665,
      "grad_norm": 5.7284836769104,
      "learning_rate": 2.645408163265306e-05,
      "loss": 0.0615,
      "step": 12000
    },
    {
      "epoch": 4.729199372056515,
      "grad_norm": 6.116998195648193,
      "learning_rate": 2.6355965463108322e-05,
      "loss": 0.0614,
      "step": 12050
    },
    {
      "epoch": 4.748822605965463,
      "grad_norm": 4.869709491729736,
      "learning_rate": 2.625784929356358e-05,
      "loss": 0.0605,
      "step": 12100
    },
    {
      "epoch": 4.768445839874412,
      "grad_norm": 7.131973743438721,
      "learning_rate": 2.6159733124018837e-05,
      "loss": 0.0607,
      "step": 12150
    },
    {
      "epoch": 4.78806907378336,
      "grad_norm": 6.118313789367676,
      "learning_rate": 2.60616169544741e-05,
      "loss": 0.0608,
      "step": 12200
    },
    {
      "epoch": 4.8076923076923075,
      "grad_norm": 5.991800308227539,
      "learning_rate": 2.5963500784929355e-05,
      "loss": 0.0602,
      "step": 12250
    },
    {
      "epoch": 4.827315541601256,
      "grad_norm": 6.812821388244629,
      "learning_rate": 2.586538461538462e-05,
      "loss": 0.0598,
      "step": 12300
    },
    {
      "epoch": 4.846938775510204,
      "grad_norm": 9.09100341796875,
      "learning_rate": 2.5767268445839877e-05,
      "loss": 0.0601,
      "step": 12350
    },
    {
      "epoch": 4.866562009419153,
      "grad_norm": 8.327081680297852,
      "learning_rate": 2.5669152276295134e-05,
      "loss": 0.0608,
      "step": 12400
    },
    {
      "epoch": 4.8861852433281,
      "grad_norm": 6.650541305541992,
      "learning_rate": 2.5571036106750395e-05,
      "loss": 0.0598,
      "step": 12450
    },
    {
      "epoch": 4.9058084772370485,
      "grad_norm": 5.574402332305908,
      "learning_rate": 2.5472919937205652e-05,
      "loss": 0.0596,
      "step": 12500
    },
    {
      "epoch": 4.925431711145997,
      "grad_norm": 7.763219356536865,
      "learning_rate": 2.537480376766091e-05,
      "loss": 0.0596,
      "step": 12550
    },
    {
      "epoch": 4.945054945054945,
      "grad_norm": 3.800077199935913,
      "learning_rate": 2.5276687598116174e-05,
      "loss": 0.0589,
      "step": 12600
    },
    {
      "epoch": 4.964678178963894,
      "grad_norm": 6.113214015960693,
      "learning_rate": 2.5178571428571428e-05,
      "loss": 0.059,
      "step": 12650
    },
    {
      "epoch": 4.984301412872841,
      "grad_norm": 4.591250419616699,
      "learning_rate": 2.5080455259026685e-05,
      "loss": 0.0576,
      "step": 12700
    },
    {
      "epoch": 5.0,
      "eval_runtime": 31.0732,
      "eval_samples_per_second": 655.806,
      "eval_steps_per_second": 20.5,
      "step": 12740
    },
    {
      "epoch": 5.0039246467817895,
      "grad_norm": 4.576958656311035,
      "learning_rate": 2.498233908948195e-05,
      "loss": 0.0587,
      "step": 12750
    },
    {
      "epoch": 5.023547880690738,
      "grad_norm": 5.785147190093994,
      "learning_rate": 2.4884222919937207e-05,
      "loss": 0.0584,
      "step": 12800
    },
    {
      "epoch": 5.043171114599686,
      "grad_norm": 3.997516632080078,
      "learning_rate": 2.4786106750392464e-05,
      "loss": 0.0576,
      "step": 12850
    },
    {
      "epoch": 5.062794348508635,
      "grad_norm": 6.015641212463379,
      "learning_rate": 2.4687990580847725e-05,
      "loss": 0.0582,
      "step": 12900
    },
    {
      "epoch": 5.082417582417582,
      "grad_norm": 4.042897701263428,
      "learning_rate": 2.4589874411302986e-05,
      "loss": 0.057,
      "step": 12950
    },
    {
      "epoch": 5.1020408163265305,
      "grad_norm": 3.788226842880249,
      "learning_rate": 2.4491758241758243e-05,
      "loss": 0.0575,
      "step": 13000
    },
    {
      "epoch": 5.121664050235479,
      "grad_norm": 3.592985153198242,
      "learning_rate": 2.43936420722135e-05,
      "loss": 0.0563,
      "step": 13050
    },
    {
      "epoch": 5.141287284144427,
      "grad_norm": 4.103283405303955,
      "learning_rate": 2.429552590266876e-05,
      "loss": 0.0566,
      "step": 13100
    },
    {
      "epoch": 5.160910518053376,
      "grad_norm": 5.5540690422058105,
      "learning_rate": 2.4197409733124022e-05,
      "loss": 0.0568,
      "step": 13150
    },
    {
      "epoch": 5.180533751962323,
      "grad_norm": 7.538069725036621,
      "learning_rate": 2.409929356357928e-05,
      "loss": 0.0569,
      "step": 13200
    },
    {
      "epoch": 5.2001569858712715,
      "grad_norm": 6.6802825927734375,
      "learning_rate": 2.4001177394034537e-05,
      "loss": 0.0566,
      "step": 13250
    },
    {
      "epoch": 5.21978021978022,
      "grad_norm": 5.267575263977051,
      "learning_rate": 2.3903061224489797e-05,
      "loss": 0.0563,
      "step": 13300
    },
    {
      "epoch": 5.239403453689168,
      "grad_norm": 4.814728260040283,
      "learning_rate": 2.3804945054945055e-05,
      "loss": 0.0571,
      "step": 13350
    },
    {
      "epoch": 5.259026687598116,
      "grad_norm": 11.17064094543457,
      "learning_rate": 2.3706828885400316e-05,
      "loss": 0.0564,
      "step": 13400
    },
    {
      "epoch": 5.278649921507064,
      "grad_norm": 4.8200154304504395,
      "learning_rate": 2.3608712715855573e-05,
      "loss": 0.0552,
      "step": 13450
    },
    {
      "epoch": 5.2982731554160125,
      "grad_norm": 4.3735270500183105,
      "learning_rate": 2.3510596546310834e-05,
      "loss": 0.0555,
      "step": 13500
    },
    {
      "epoch": 5.317896389324961,
      "grad_norm": 6.550560474395752,
      "learning_rate": 2.341248037676609e-05,
      "loss": 0.0551,
      "step": 13550
    },
    {
      "epoch": 5.337519623233909,
      "grad_norm": 5.571530342102051,
      "learning_rate": 2.3314364207221352e-05,
      "loss": 0.055,
      "step": 13600
    },
    {
      "epoch": 5.357142857142857,
      "grad_norm": 7.0756144523620605,
      "learning_rate": 2.321624803767661e-05,
      "loss": 0.0554,
      "step": 13650
    },
    {
      "epoch": 5.376766091051805,
      "grad_norm": 4.865004062652588,
      "learning_rate": 2.311813186813187e-05,
      "loss": 0.0562,
      "step": 13700
    },
    {
      "epoch": 5.3963893249607535,
      "grad_norm": 4.002989768981934,
      "learning_rate": 2.3020015698587127e-05,
      "loss": 0.055,
      "step": 13750
    },
    {
      "epoch": 5.416012558869702,
      "grad_norm": 4.256368160247803,
      "learning_rate": 2.2921899529042388e-05,
      "loss": 0.0541,
      "step": 13800
    },
    {
      "epoch": 5.43563579277865,
      "grad_norm": 2.8333218097686768,
      "learning_rate": 2.2823783359497646e-05,
      "loss": 0.0546,
      "step": 13850
    },
    {
      "epoch": 5.455259026687598,
      "grad_norm": 3.638258695602417,
      "learning_rate": 2.2725667189952906e-05,
      "loss": 0.0543,
      "step": 13900
    },
    {
      "epoch": 5.474882260596546,
      "grad_norm": 4.692948341369629,
      "learning_rate": 2.2627551020408164e-05,
      "loss": 0.0543,
      "step": 13950
    },
    {
      "epoch": 5.4945054945054945,
      "grad_norm": 4.171496868133545,
      "learning_rate": 2.2529434850863425e-05,
      "loss": 0.0545,
      "step": 14000
    },
    {
      "epoch": 5.514128728414443,
      "grad_norm": 4.7860798835754395,
      "learning_rate": 2.2431318681318682e-05,
      "loss": 0.0532,
      "step": 14050
    },
    {
      "epoch": 5.533751962323391,
      "grad_norm": 6.008090496063232,
      "learning_rate": 2.233320251177394e-05,
      "loss": 0.0536,
      "step": 14100
    },
    {
      "epoch": 5.553375196232339,
      "grad_norm": 5.223602771759033,
      "learning_rate": 2.22350863422292e-05,
      "loss": 0.0534,
      "step": 14150
    },
    {
      "epoch": 5.572998430141287,
      "grad_norm": 4.850787162780762,
      "learning_rate": 2.213697017268446e-05,
      "loss": 0.0527,
      "step": 14200
    },
    {
      "epoch": 5.5926216640502355,
      "grad_norm": 4.774037837982178,
      "learning_rate": 2.2038854003139718e-05,
      "loss": 0.0527,
      "step": 14250
    },
    {
      "epoch": 5.612244897959184,
      "grad_norm": 5.041175842285156,
      "learning_rate": 2.1940737833594976e-05,
      "loss": 0.0527,
      "step": 14300
    },
    {
      "epoch": 5.631868131868131,
      "grad_norm": 3.794559955596924,
      "learning_rate": 2.1842621664050236e-05,
      "loss": 0.0538,
      "step": 14350
    },
    {
      "epoch": 5.65149136577708,
      "grad_norm": 3.659008264541626,
      "learning_rate": 2.1744505494505497e-05,
      "loss": 0.0525,
      "step": 14400
    },
    {
      "epoch": 5.671114599686028,
      "grad_norm": 3.4157819747924805,
      "learning_rate": 2.1646389324960755e-05,
      "loss": 0.0524,
      "step": 14450
    },
    {
      "epoch": 5.6907378335949765,
      "grad_norm": 7.122867584228516,
      "learning_rate": 2.1548273155416012e-05,
      "loss": 0.0526,
      "step": 14500
    },
    {
      "epoch": 5.710361067503925,
      "grad_norm": 6.289924144744873,
      "learning_rate": 2.1450156985871273e-05,
      "loss": 0.0531,
      "step": 14550
    },
    {
      "epoch": 5.729984301412873,
      "grad_norm": 3.5295791625976562,
      "learning_rate": 2.1352040816326533e-05,
      "loss": 0.0523,
      "step": 14600
    },
    {
      "epoch": 5.749607535321821,
      "grad_norm": 6.2352070808410645,
      "learning_rate": 2.125392464678179e-05,
      "loss": 0.0525,
      "step": 14650
    },
    {
      "epoch": 5.769230769230769,
      "grad_norm": 5.447988510131836,
      "learning_rate": 2.1155808477237048e-05,
      "loss": 0.0507,
      "step": 14700
    },
    {
      "epoch": 5.7888540031397175,
      "grad_norm": 5.120284557342529,
      "learning_rate": 2.105769230769231e-05,
      "loss": 0.052,
      "step": 14750
    },
    {
      "epoch": 5.808477237048666,
      "grad_norm": 3.095414161682129,
      "learning_rate": 2.095957613814757e-05,
      "loss": 0.0516,
      "step": 14800
    },
    {
      "epoch": 5.828100470957613,
      "grad_norm": 3.375783681869507,
      "learning_rate": 2.0861459968602827e-05,
      "loss": 0.0516,
      "step": 14850
    },
    {
      "epoch": 5.847723704866562,
      "grad_norm": 5.972737789154053,
      "learning_rate": 2.0763343799058085e-05,
      "loss": 0.052,
      "step": 14900
    },
    {
      "epoch": 5.86734693877551,
      "grad_norm": 4.821335315704346,
      "learning_rate": 2.0665227629513345e-05,
      "loss": 0.0509,
      "step": 14950
    },
    {
      "epoch": 5.8869701726844585,
      "grad_norm": 4.1835713386535645,
      "learning_rate": 2.0567111459968606e-05,
      "loss": 0.0514,
      "step": 15000
    },
    {
      "epoch": 5.906593406593407,
      "grad_norm": 4.8077874183654785,
      "learning_rate": 2.0468995290423863e-05,
      "loss": 0.051,
      "step": 15050
    },
    {
      "epoch": 5.926216640502354,
      "grad_norm": 4.451551914215088,
      "learning_rate": 2.037087912087912e-05,
      "loss": 0.0507,
      "step": 15100
    },
    {
      "epoch": 5.945839874411303,
      "grad_norm": 6.0693359375,
      "learning_rate": 2.027276295133438e-05,
      "loss": 0.0508,
      "step": 15150
    },
    {
      "epoch": 5.965463108320251,
      "grad_norm": 4.677000999450684,
      "learning_rate": 2.0174646781789642e-05,
      "loss": 0.0509,
      "step": 15200
    },
    {
      "epoch": 5.9850863422291996,
      "grad_norm": 6.383735656738281,
      "learning_rate": 2.00765306122449e-05,
      "loss": 0.0509,
      "step": 15250
    },
    {
      "epoch": 6.0,
      "eval_runtime": 31.238,
      "eval_samples_per_second": 652.347,
      "eval_steps_per_second": 20.392,
      "step": 15288
    },
    {
      "epoch": 6.004709576138148,
      "grad_norm": 4.1936187744140625,
      "learning_rate": 1.9978414442700157e-05,
      "loss": 0.0499,
      "step": 15300
    },
    {
      "epoch": 6.024332810047095,
      "grad_norm": 9.358732223510742,
      "learning_rate": 1.9880298273155418e-05,
      "loss": 0.0499,
      "step": 15350
    },
    {
      "epoch": 6.043956043956044,
      "grad_norm": 3.3407368659973145,
      "learning_rate": 1.9782182103610675e-05,
      "loss": 0.0504,
      "step": 15400
    },
    {
      "epoch": 6.063579277864992,
      "grad_norm": 5.138937950134277,
      "learning_rate": 1.9684065934065936e-05,
      "loss": 0.0508,
      "step": 15450
    },
    {
      "epoch": 6.083202511773941,
      "grad_norm": 4.687673568725586,
      "learning_rate": 1.9585949764521193e-05,
      "loss": 0.0504,
      "step": 15500
    },
    {
      "epoch": 6.102825745682889,
      "grad_norm": 4.343059539794922,
      "learning_rate": 1.9487833594976454e-05,
      "loss": 0.0501,
      "step": 15550
    },
    {
      "epoch": 6.122448979591836,
      "grad_norm": 4.01627779006958,
      "learning_rate": 1.938971742543171e-05,
      "loss": 0.0493,
      "step": 15600
    },
    {
      "epoch": 6.142072213500785,
      "grad_norm": 5.082857608795166,
      "learning_rate": 1.9291601255886972e-05,
      "loss": 0.0494,
      "step": 15650
    },
    {
      "epoch": 6.161695447409733,
      "grad_norm": 4.429504871368408,
      "learning_rate": 1.919348508634223e-05,
      "loss": 0.0493,
      "step": 15700
    },
    {
      "epoch": 6.181318681318682,
      "grad_norm": 7.85584831237793,
      "learning_rate": 1.909536891679749e-05,
      "loss": 0.0501,
      "step": 15750
    },
    {
      "epoch": 6.20094191522763,
      "grad_norm": 7.44658899307251,
      "learning_rate": 1.8997252747252748e-05,
      "loss": 0.0488,
      "step": 15800
    },
    {
      "epoch": 6.220565149136577,
      "grad_norm": 6.193772792816162,
      "learning_rate": 1.889913657770801e-05,
      "loss": 0.0483,
      "step": 15850
    },
    {
      "epoch": 6.240188383045526,
      "grad_norm": 5.06171989440918,
      "learning_rate": 1.8801020408163266e-05,
      "loss": 0.049,
      "step": 15900
    },
    {
      "epoch": 6.259811616954474,
      "grad_norm": 6.914418697357178,
      "learning_rate": 1.8702904238618527e-05,
      "loss": 0.0489,
      "step": 15950
    },
    {
      "epoch": 6.279434850863423,
      "grad_norm": 5.810369968414307,
      "learning_rate": 1.8604788069073784e-05,
      "loss": 0.0487,
      "step": 16000
    },
    {
      "epoch": 6.299058084772371,
      "grad_norm": 6.2283406257629395,
      "learning_rate": 1.8506671899529045e-05,
      "loss": 0.0486,
      "step": 16050
    },
    {
      "epoch": 6.318681318681318,
      "grad_norm": 4.013928413391113,
      "learning_rate": 1.8408555729984302e-05,
      "loss": 0.0483,
      "step": 16100
    },
    {
      "epoch": 6.338304552590267,
      "grad_norm": 4.968646049499512,
      "learning_rate": 1.831043956043956e-05,
      "loss": 0.0483,
      "step": 16150
    },
    {
      "epoch": 6.357927786499215,
      "grad_norm": 2.469428062438965,
      "learning_rate": 1.821232339089482e-05,
      "loss": 0.0478,
      "step": 16200
    },
    {
      "epoch": 6.377551020408164,
      "grad_norm": 3.83870005607605,
      "learning_rate": 1.811420722135008e-05,
      "loss": 0.0483,
      "step": 16250
    },
    {
      "epoch": 6.397174254317111,
      "grad_norm": 3.9209132194519043,
      "learning_rate": 1.801609105180534e-05,
      "loss": 0.0478,
      "step": 16300
    },
    {
      "epoch": 6.416797488226059,
      "grad_norm": 4.573362350463867,
      "learning_rate": 1.7917974882260596e-05,
      "loss": 0.0474,
      "step": 16350
    },
    {
      "epoch": 6.436420722135008,
      "grad_norm": 3.43326473236084,
      "learning_rate": 1.7819858712715857e-05,
      "loss": 0.0479,
      "step": 16400
    },
    {
      "epoch": 6.456043956043956,
      "grad_norm": 4.58020544052124,
      "learning_rate": 1.7721742543171118e-05,
      "loss": 0.0471,
      "step": 16450
    },
    {
      "epoch": 6.475667189952905,
      "grad_norm": 3.7460849285125732,
      "learning_rate": 1.7623626373626375e-05,
      "loss": 0.0473,
      "step": 16500
    },
    {
      "epoch": 6.495290423861852,
      "grad_norm": 5.121698379516602,
      "learning_rate": 1.7525510204081632e-05,
      "loss": 0.0475,
      "step": 16550
    },
    {
      "epoch": 6.5149136577708004,
      "grad_norm": 3.5314903259277344,
      "learning_rate": 1.7427394034536893e-05,
      "loss": 0.0477,
      "step": 16600
    },
    {
      "epoch": 6.534536891679749,
      "grad_norm": 4.35614013671875,
      "learning_rate": 1.7329277864992154e-05,
      "loss": 0.0464,
      "step": 16650
    },
    {
      "epoch": 6.554160125588697,
      "grad_norm": 5.825592517852783,
      "learning_rate": 1.7231161695447408e-05,
      "loss": 0.0475,
      "step": 16700
    },
    {
      "epoch": 6.573783359497646,
      "grad_norm": 3.477895736694336,
      "learning_rate": 1.713304552590267e-05,
      "loss": 0.0471,
      "step": 16750
    },
    {
      "epoch": 6.593406593406593,
      "grad_norm": 5.470231056213379,
      "learning_rate": 1.703492935635793e-05,
      "loss": 0.0462,
      "step": 16800
    },
    {
      "epoch": 6.6130298273155415,
      "grad_norm": 3.3613972663879395,
      "learning_rate": 1.693681318681319e-05,
      "loss": 0.0469,
      "step": 16850
    },
    {
      "epoch": 6.63265306122449,
      "grad_norm": 5.097018718719482,
      "learning_rate": 1.6838697017268444e-05,
      "loss": 0.0464,
      "step": 16900
    },
    {
      "epoch": 6.652276295133438,
      "grad_norm": 3.562755584716797,
      "learning_rate": 1.6740580847723705e-05,
      "loss": 0.0465,
      "step": 16950
    },
    {
      "epoch": 6.671899529042387,
      "grad_norm": 3.947288990020752,
      "learning_rate": 1.6642464678178966e-05,
      "loss": 0.0462,
      "step": 17000
    },
    {
      "epoch": 6.691522762951334,
      "grad_norm": 4.048359394073486,
      "learning_rate": 1.6544348508634226e-05,
      "loss": 0.0461,
      "step": 17050
    },
    {
      "epoch": 6.7111459968602825,
      "grad_norm": 4.337855815887451,
      "learning_rate": 1.644623233908948e-05,
      "loss": 0.0457,
      "step": 17100
    },
    {
      "epoch": 6.730769230769231,
      "grad_norm": 4.40978479385376,
      "learning_rate": 1.634811616954474e-05,
      "loss": 0.0463,
      "step": 17150
    },
    {
      "epoch": 6.750392464678179,
      "grad_norm": 6.866671085357666,
      "learning_rate": 1.6250000000000002e-05,
      "loss": 0.0461,
      "step": 17200
    },
    {
      "epoch": 6.770015698587127,
      "grad_norm": 2.77496337890625,
      "learning_rate": 1.6151883830455263e-05,
      "loss": 0.046,
      "step": 17250
    },
    {
      "epoch": 6.789638932496075,
      "grad_norm": 5.310593605041504,
      "learning_rate": 1.6053767660910517e-05,
      "loss": 0.0449,
      "step": 17300
    },
    {
      "epoch": 6.8092621664050235,
      "grad_norm": 5.36250638961792,
      "learning_rate": 1.5955651491365777e-05,
      "loss": 0.0455,
      "step": 17350
    },
    {
      "epoch": 6.828885400313972,
      "grad_norm": 5.637259483337402,
      "learning_rate": 1.5857535321821038e-05,
      "loss": 0.0447,
      "step": 17400
    },
    {
      "epoch": 6.84850863422292,
      "grad_norm": 3.7877707481384277,
      "learning_rate": 1.5759419152276296e-05,
      "loss": 0.0453,
      "step": 17450
    },
    {
      "epoch": 6.868131868131869,
      "grad_norm": 3.752359390258789,
      "learning_rate": 1.5661302982731553e-05,
      "loss": 0.0455,
      "step": 17500
    },
    {
      "epoch": 6.887755102040816,
      "grad_norm": 3.287236213684082,
      "learning_rate": 1.5563186813186814e-05,
      "loss": 0.046,
      "step": 17550
    },
    {
      "epoch": 6.9073783359497645,
      "grad_norm": 5.3540544509887695,
      "learning_rate": 1.5465070643642075e-05,
      "loss": 0.0449,
      "step": 17600
    },
    {
      "epoch": 6.927001569858713,
      "grad_norm": 4.048921585083008,
      "learning_rate": 1.5366954474097332e-05,
      "loss": 0.0453,
      "step": 17650
    },
    {
      "epoch": 6.946624803767661,
      "grad_norm": 4.901269912719727,
      "learning_rate": 1.526883830455259e-05,
      "loss": 0.045,
      "step": 17700
    },
    {
      "epoch": 6.966248037676609,
      "grad_norm": 3.382913112640381,
      "learning_rate": 1.517072213500785e-05,
      "loss": 0.0451,
      "step": 17750
    },
    {
      "epoch": 6.985871271585557,
      "grad_norm": 2.9782750606536865,
      "learning_rate": 1.5072605965463111e-05,
      "loss": 0.0452,
      "step": 17800
    },
    {
      "epoch": 7.0,
      "eval_runtime": 31.3175,
      "eval_samples_per_second": 650.691,
      "eval_steps_per_second": 20.34,
      "step": 17836
    },
    {
      "epoch": 7.0054945054945055,
      "grad_norm": 5.809114456176758,
      "learning_rate": 1.4974489795918367e-05,
      "loss": 0.045,
      "step": 17850
    },
    {
      "epoch": 7.025117739403454,
      "grad_norm": 4.957948207855225,
      "learning_rate": 1.4876373626373627e-05,
      "loss": 0.0453,
      "step": 17900
    },
    {
      "epoch": 7.044740973312402,
      "grad_norm": 3.615780830383301,
      "learning_rate": 1.4778257456828886e-05,
      "loss": 0.0449,
      "step": 17950
    },
    {
      "epoch": 7.06436420722135,
      "grad_norm": 7.368683338165283,
      "learning_rate": 1.4680141287284147e-05,
      "loss": 0.0444,
      "step": 18000
    },
    {
      "epoch": 7.083987441130298,
      "grad_norm": 2.341625928878784,
      "learning_rate": 1.4582025117739403e-05,
      "loss": 0.0443,
      "step": 18050
    },
    {
      "epoch": 7.1036106750392465,
      "grad_norm": 7.731785774230957,
      "learning_rate": 1.4483908948194664e-05,
      "loss": 0.0445,
      "step": 18100
    },
    {
      "epoch": 7.123233908948195,
      "grad_norm": 3.1834030151367188,
      "learning_rate": 1.4385792778649923e-05,
      "loss": 0.0438,
      "step": 18150
    },
    {
      "epoch": 7.142857142857143,
      "grad_norm": 4.904422283172607,
      "learning_rate": 1.428767660910518e-05,
      "loss": 0.0439,
      "step": 18200
    },
    {
      "epoch": 7.162480376766091,
      "grad_norm": 4.031137466430664,
      "learning_rate": 1.418956043956044e-05,
      "loss": 0.0433,
      "step": 18250
    },
    {
      "epoch": 7.182103610675039,
      "grad_norm": 5.019742012023926,
      "learning_rate": 1.40914442700157e-05,
      "loss": 0.0443,
      "step": 18300
    },
    {
      "epoch": 7.2017268445839875,
      "grad_norm": 3.516237258911133,
      "learning_rate": 1.3993328100470959e-05,
      "loss": 0.0438,
      "step": 18350
    },
    {
      "epoch": 7.221350078492936,
      "grad_norm": 4.747323989868164,
      "learning_rate": 1.3895211930926216e-05,
      "loss": 0.0433,
      "step": 18400
    },
    {
      "epoch": 7.240973312401884,
      "grad_norm": 5.919980049133301,
      "learning_rate": 1.3797095761381475e-05,
      "loss": 0.0441,
      "step": 18450
    },
    {
      "epoch": 7.260596546310832,
      "grad_norm": 4.379401683807373,
      "learning_rate": 1.3698979591836736e-05,
      "loss": 0.0437,
      "step": 18500
    },
    {
      "epoch": 7.28021978021978,
      "grad_norm": 6.432582855224609,
      "learning_rate": 1.3600863422291995e-05,
      "loss": 0.0437,
      "step": 18550
    },
    {
      "epoch": 7.2998430141287285,
      "grad_norm": 2.4287431240081787,
      "learning_rate": 1.3502747252747253e-05,
      "loss": 0.0431,
      "step": 18600
    },
    {
      "epoch": 7.319466248037677,
      "grad_norm": 4.1932373046875,
      "learning_rate": 1.3404631083202512e-05,
      "loss": 0.043,
      "step": 18650
    },
    {
      "epoch": 7.339089481946624,
      "grad_norm": 5.0555548667907715,
      "learning_rate": 1.3306514913657773e-05,
      "loss": 0.0432,
      "step": 18700
    },
    {
      "epoch": 7.358712715855573,
      "grad_norm": 4.120007514953613,
      "learning_rate": 1.320839874411303e-05,
      "loss": 0.0426,
      "step": 18750
    },
    {
      "epoch": 7.378335949764521,
      "grad_norm": 3.5506820678710938,
      "learning_rate": 1.3110282574568289e-05,
      "loss": 0.0434,
      "step": 18800
    },
    {
      "epoch": 7.3979591836734695,
      "grad_norm": 4.949825763702393,
      "learning_rate": 1.3012166405023548e-05,
      "loss": 0.0432,
      "step": 18850
    },
    {
      "epoch": 7.417582417582418,
      "grad_norm": 5.293485641479492,
      "learning_rate": 1.2914050235478809e-05,
      "loss": 0.043,
      "step": 18900
    },
    {
      "epoch": 7.437205651491365,
      "grad_norm": 4.78484582901001,
      "learning_rate": 1.2815934065934066e-05,
      "loss": 0.0427,
      "step": 18950
    },
    {
      "epoch": 7.456828885400314,
      "grad_norm": 4.551872730255127,
      "learning_rate": 1.2717817896389325e-05,
      "loss": 0.0428,
      "step": 19000
    },
    {
      "epoch": 7.476452119309262,
      "grad_norm": 2.952465534210205,
      "learning_rate": 1.2619701726844584e-05,
      "loss": 0.0427,
      "step": 19050
    },
    {
      "epoch": 7.4960753532182105,
      "grad_norm": 2.958359956741333,
      "learning_rate": 1.2521585557299845e-05,
      "loss": 0.0425,
      "step": 19100
    },
    {
      "epoch": 7.515698587127159,
      "grad_norm": 4.8837480545043945,
      "learning_rate": 1.2423469387755103e-05,
      "loss": 0.043,
      "step": 19150
    },
    {
      "epoch": 7.535321821036106,
      "grad_norm": 4.46743106842041,
      "learning_rate": 1.2325353218210362e-05,
      "loss": 0.0421,
      "step": 19200
    },
    {
      "epoch": 7.554945054945055,
      "grad_norm": 4.058477401733398,
      "learning_rate": 1.222723704866562e-05,
      "loss": 0.0424,
      "step": 19250
    },
    {
      "epoch": 7.574568288854003,
      "grad_norm": 1.9828184843063354,
      "learning_rate": 1.212912087912088e-05,
      "loss": 0.0425,
      "step": 19300
    },
    {
      "epoch": 7.5941915227629515,
      "grad_norm": 2.4220480918884277,
      "learning_rate": 1.2031004709576139e-05,
      "loss": 0.0424,
      "step": 19350
    },
    {
      "epoch": 7.6138147566719,
      "grad_norm": 5.406793594360352,
      "learning_rate": 1.1932888540031398e-05,
      "loss": 0.0424,
      "step": 19400
    },
    {
      "epoch": 7.633437990580847,
      "grad_norm": 5.655592441558838,
      "learning_rate": 1.1834772370486657e-05,
      "loss": 0.0425,
      "step": 19450
    },
    {
      "epoch": 7.653061224489796,
      "grad_norm": 4.634084701538086,
      "learning_rate": 1.1736656200941916e-05,
      "loss": 0.0423,
      "step": 19500
    },
    {
      "epoch": 7.672684458398744,
      "grad_norm": 3.889091730117798,
      "learning_rate": 1.1638540031397175e-05,
      "loss": 0.0423,
      "step": 19550
    },
    {
      "epoch": 7.6923076923076925,
      "grad_norm": 3.6467700004577637,
      "learning_rate": 1.1540423861852434e-05,
      "loss": 0.0425,
      "step": 19600
    },
    {
      "epoch": 7.71193092621664,
      "grad_norm": 2.925867795944214,
      "learning_rate": 1.1442307692307693e-05,
      "loss": 0.0412,
      "step": 19650
    },
    {
      "epoch": 7.731554160125588,
      "grad_norm": 3.6592392921447754,
      "learning_rate": 1.1344191522762952e-05,
      "loss": 0.0418,
      "step": 19700
    },
    {
      "epoch": 7.751177394034537,
      "grad_norm": 3.032058000564575,
      "learning_rate": 1.1246075353218211e-05,
      "loss": 0.0416,
      "step": 19750
    },
    {
      "epoch": 7.770800627943485,
      "grad_norm": 4.768063545227051,
      "learning_rate": 1.114795918367347e-05,
      "loss": 0.0418,
      "step": 19800
    },
    {
      "epoch": 7.7904238618524335,
      "grad_norm": 3.679297924041748,
      "learning_rate": 1.104984301412873e-05,
      "loss": 0.041,
      "step": 19850
    },
    {
      "epoch": 7.810047095761382,
      "grad_norm": 4.556107997894287,
      "learning_rate": 1.0951726844583989e-05,
      "loss": 0.0419,
      "step": 19900
    },
    {
      "epoch": 7.829670329670329,
      "grad_norm": 5.239830493927002,
      "learning_rate": 1.0853610675039248e-05,
      "loss": 0.0413,
      "step": 19950
    },
    {
      "epoch": 7.849293563579278,
      "grad_norm": 3.9303929805755615,
      "learning_rate": 1.0755494505494507e-05,
      "loss": 0.0413,
      "step": 20000
    },
    {
      "epoch": 7.868916797488226,
      "grad_norm": 4.162350177764893,
      "learning_rate": 1.0657378335949766e-05,
      "loss": 0.0418,
      "step": 20050
    },
    {
      "epoch": 7.8885400313971745,
      "grad_norm": 3.876286268234253,
      "learning_rate": 1.0559262166405023e-05,
      "loss": 0.0418,
      "step": 20100
    },
    {
      "epoch": 7.908163265306122,
      "grad_norm": 3.650744915008545,
      "learning_rate": 1.0461145996860284e-05,
      "loss": 0.041,
      "step": 20150
    },
    {
      "epoch": 7.92778649921507,
      "grad_norm": 3.8634378910064697,
      "learning_rate": 1.0363029827315541e-05,
      "loss": 0.0408,
      "step": 20200
    },
    {
      "epoch": 7.947409733124019,
      "grad_norm": 2.700838088989258,
      "learning_rate": 1.0264913657770802e-05,
      "loss": 0.041,
      "step": 20250
    },
    {
      "epoch": 7.967032967032967,
      "grad_norm": 5.270754814147949,
      "learning_rate": 1.016679748822606e-05,
      "loss": 0.041,
      "step": 20300
    },
    {
      "epoch": 7.9866562009419155,
      "grad_norm": 3.726253032684326,
      "learning_rate": 1.006868131868132e-05,
      "loss": 0.0411,
      "step": 20350
    },
    {
      "epoch": 8.0,
      "eval_runtime": 31.3026,
      "eval_samples_per_second": 651.001,
      "eval_steps_per_second": 20.35,
      "step": 20384
    },
    {
      "epoch": 8.006279434850864,
      "grad_norm": 3.103233814239502,
      "learning_rate": 9.970565149136578e-06,
      "loss": 0.0412,
      "step": 20400
    },
    {
      "epoch": 8.025902668759812,
      "grad_norm": 3.7846193313598633,
      "learning_rate": 9.872448979591838e-06,
      "loss": 0.0406,
      "step": 20450
    },
    {
      "epoch": 8.04552590266876,
      "grad_norm": 2.903621196746826,
      "learning_rate": 9.774332810047096e-06,
      "loss": 0.0406,
      "step": 20500
    },
    {
      "epoch": 8.065149136577707,
      "grad_norm": 2.9327242374420166,
      "learning_rate": 9.676216640502357e-06,
      "loss": 0.0411,
      "step": 20550
    },
    {
      "epoch": 8.084772370486656,
      "grad_norm": 3.5880658626556396,
      "learning_rate": 9.578100470957614e-06,
      "loss": 0.0401,
      "step": 20600
    },
    {
      "epoch": 8.104395604395604,
      "grad_norm": 3.6474032402038574,
      "learning_rate": 9.479984301412873e-06,
      "loss": 0.0408,
      "step": 20650
    },
    {
      "epoch": 8.124018838304552,
      "grad_norm": 3.401280641555786,
      "learning_rate": 9.381868131868132e-06,
      "loss": 0.0405,
      "step": 20700
    },
    {
      "epoch": 8.1436420722135,
      "grad_norm": 3.0134148597717285,
      "learning_rate": 9.283751962323391e-06,
      "loss": 0.04,
      "step": 20750
    },
    {
      "epoch": 8.16326530612245,
      "grad_norm": 5.658895015716553,
      "learning_rate": 9.18563579277865e-06,
      "loss": 0.0401,
      "step": 20800
    },
    {
      "epoch": 8.182888540031398,
      "grad_norm": 3.6624879837036133,
      "learning_rate": 9.08751962323391e-06,
      "loss": 0.0405,
      "step": 20850
    },
    {
      "epoch": 8.202511773940346,
      "grad_norm": 4.6433844566345215,
      "learning_rate": 8.989403453689168e-06,
      "loss": 0.0401,
      "step": 20900
    },
    {
      "epoch": 8.222135007849294,
      "grad_norm": 5.427285671234131,
      "learning_rate": 8.891287284144428e-06,
      "loss": 0.0395,
      "step": 20950
    },
    {
      "epoch": 8.241758241758241,
      "grad_norm": 3.2660093307495117,
      "learning_rate": 8.793171114599687e-06,
      "loss": 0.0402,
      "step": 21000
    },
    {
      "epoch": 8.26138147566719,
      "grad_norm": 2.176631212234497,
      "learning_rate": 8.695054945054946e-06,
      "loss": 0.0394,
      "step": 21050
    },
    {
      "epoch": 8.281004709576138,
      "grad_norm": 2.6654152870178223,
      "learning_rate": 8.596938775510205e-06,
      "loss": 0.0402,
      "step": 21100
    },
    {
      "epoch": 8.300627943485086,
      "grad_norm": 4.599706172943115,
      "learning_rate": 8.498822605965464e-06,
      "loss": 0.0408,
      "step": 21150
    },
    {
      "epoch": 8.320251177394034,
      "grad_norm": 2.709930181503296,
      "learning_rate": 8.400706436420723e-06,
      "loss": 0.0403,
      "step": 21200
    },
    {
      "epoch": 8.339874411302983,
      "grad_norm": 2.1478466987609863,
      "learning_rate": 8.302590266875982e-06,
      "loss": 0.0397,
      "step": 21250
    },
    {
      "epoch": 8.359497645211931,
      "grad_norm": 3.7060396671295166,
      "learning_rate": 8.204474097331241e-06,
      "loss": 0.04,
      "step": 21300
    },
    {
      "epoch": 8.37912087912088,
      "grad_norm": 3.5475525856018066,
      "learning_rate": 8.1063579277865e-06,
      "loss": 0.0398,
      "step": 21350
    },
    {
      "epoch": 8.398744113029828,
      "grad_norm": 3.4517710208892822,
      "learning_rate": 8.00824175824176e-06,
      "loss": 0.0396,
      "step": 21400
    },
    {
      "epoch": 8.418367346938776,
      "grad_norm": 3.8303725719451904,
      "learning_rate": 7.910125588697018e-06,
      "loss": 0.0393,
      "step": 21450
    },
    {
      "epoch": 8.437990580847723,
      "grad_norm": 4.1559319496154785,
      "learning_rate": 7.812009419152276e-06,
      "loss": 0.0391,
      "step": 21500
    },
    {
      "epoch": 8.457613814756671,
      "grad_norm": 2.5383167266845703,
      "learning_rate": 7.713893249607536e-06,
      "loss": 0.0389,
      "step": 21550
    },
    {
      "epoch": 8.47723704866562,
      "grad_norm": 4.976914405822754,
      "learning_rate": 7.615777080062794e-06,
      "loss": 0.0396,
      "step": 21600
    },
    {
      "epoch": 8.496860282574568,
      "grad_norm": 2.3149824142456055,
      "learning_rate": 7.517660910518054e-06,
      "loss": 0.0388,
      "step": 21650
    },
    {
      "epoch": 8.516483516483516,
      "grad_norm": 3.217759132385254,
      "learning_rate": 7.419544740973312e-06,
      "loss": 0.039,
      "step": 21700
    },
    {
      "epoch": 8.536106750392465,
      "grad_norm": 3.802926778793335,
      "learning_rate": 7.321428571428572e-06,
      "loss": 0.0394,
      "step": 21750
    },
    {
      "epoch": 8.555729984301413,
      "grad_norm": 3.0720932483673096,
      "learning_rate": 7.22331240188383e-06,
      "loss": 0.0396,
      "step": 21800
    },
    {
      "epoch": 8.575353218210362,
      "grad_norm": 3.360233783721924,
      "learning_rate": 7.12519623233909e-06,
      "loss": 0.039,
      "step": 21850
    },
    {
      "epoch": 8.59497645211931,
      "grad_norm": 4.380945682525635,
      "learning_rate": 7.027080062794348e-06,
      "loss": 0.0387,
      "step": 21900
    },
    {
      "epoch": 8.614599686028257,
      "grad_norm": 3.594543218612671,
      "learning_rate": 6.928963893249608e-06,
      "loss": 0.039,
      "step": 21950
    },
    {
      "epoch": 8.634222919937205,
      "grad_norm": 5.083856105804443,
      "learning_rate": 6.830847723704866e-06,
      "loss": 0.0387,
      "step": 22000
    },
    {
      "epoch": 8.653846153846153,
      "grad_norm": 3.724590301513672,
      "learning_rate": 6.732731554160126e-06,
      "loss": 0.0389,
      "step": 22050
    },
    {
      "epoch": 8.673469387755102,
      "grad_norm": 1.939574956893921,
      "learning_rate": 6.6346153846153846e-06,
      "loss": 0.0386,
      "step": 22100
    },
    {
      "epoch": 8.69309262166405,
      "grad_norm": 6.941518306732178,
      "learning_rate": 6.536499215070644e-06,
      "loss": 0.0393,
      "step": 22150
    },
    {
      "epoch": 8.712715855572998,
      "grad_norm": 3.982689142227173,
      "learning_rate": 6.438383045525903e-06,
      "loss": 0.0388,
      "step": 22200
    },
    {
      "epoch": 8.732339089481947,
      "grad_norm": 2.178544759750366,
      "learning_rate": 6.340266875981162e-06,
      "loss": 0.039,
      "step": 22250
    },
    {
      "epoch": 8.751962323390895,
      "grad_norm": 3.1581332683563232,
      "learning_rate": 6.242150706436421e-06,
      "loss": 0.0391,
      "step": 22300
    },
    {
      "epoch": 8.771585557299844,
      "grad_norm": 3.656170129776001,
      "learning_rate": 6.14403453689168e-06,
      "loss": 0.0387,
      "step": 22350
    },
    {
      "epoch": 8.791208791208792,
      "grad_norm": 4.340782165527344,
      "learning_rate": 6.045918367346939e-06,
      "loss": 0.0387,
      "step": 22400
    },
    {
      "epoch": 8.81083202511774,
      "grad_norm": 2.1362903118133545,
      "learning_rate": 5.947802197802198e-06,
      "loss": 0.0385,
      "step": 22450
    },
    {
      "epoch": 8.830455259026687,
      "grad_norm": 3.1193766593933105,
      "learning_rate": 5.849686028257457e-06,
      "loss": 0.0383,
      "step": 22500
    },
    {
      "epoch": 8.850078492935635,
      "grad_norm": 3.092552661895752,
      "learning_rate": 5.751569858712716e-06,
      "loss": 0.0384,
      "step": 22550
    },
    {
      "epoch": 8.869701726844584,
      "grad_norm": 3.480252981185913,
      "learning_rate": 5.653453689167975e-06,
      "loss": 0.0388,
      "step": 22600
    },
    {
      "epoch": 8.889324960753532,
      "grad_norm": 4.534541130065918,
      "learning_rate": 5.555337519623234e-06,
      "loss": 0.0383,
      "step": 22650
    },
    {
      "epoch": 8.90894819466248,
      "grad_norm": 2.823655128479004,
      "learning_rate": 5.4572213500784935e-06,
      "loss": 0.038,
      "step": 22700
    },
    {
      "epoch": 8.928571428571429,
      "grad_norm": 3.151813507080078,
      "learning_rate": 5.3591051805337525e-06,
      "loss": 0.0382,
      "step": 22750
    },
    {
      "epoch": 8.948194662480377,
      "grad_norm": 1.856201171875,
      "learning_rate": 5.260989010989012e-06,
      "loss": 0.0387,
      "step": 22800
    },
    {
      "epoch": 8.967817896389326,
      "grad_norm": 3.599609613418579,
      "learning_rate": 5.162872841444271e-06,
      "loss": 0.0385,
      "step": 22850
    },
    {
      "epoch": 8.987441130298274,
      "grad_norm": 4.29255485534668,
      "learning_rate": 5.06475667189953e-06,
      "loss": 0.0384,
      "step": 22900
    },
    {
      "epoch": 9.0,
      "eval_runtime": 31.3324,
      "eval_samples_per_second": 650.381,
      "eval_steps_per_second": 20.33,
      "step": 22932
    },
    {
      "epoch": 9.00706436420722,
      "grad_norm": 5.2991437911987305,
      "learning_rate": 4.966640502354789e-06,
      "loss": 0.038,
      "step": 22950
    },
    {
      "epoch": 9.026687598116169,
      "grad_norm": 3.3497889041900635,
      "learning_rate": 4.868524332810048e-06,
      "loss": 0.0379,
      "step": 23000
    },
    {
      "epoch": 9.046310832025117,
      "grad_norm": 3.743901014328003,
      "learning_rate": 4.770408163265307e-06,
      "loss": 0.0376,
      "step": 23050
    },
    {
      "epoch": 9.065934065934066,
      "grad_norm": 3.112907886505127,
      "learning_rate": 4.672291993720565e-06,
      "loss": 0.0386,
      "step": 23100
    },
    {
      "epoch": 9.085557299843014,
      "grad_norm": 2.32016658782959,
      "learning_rate": 4.574175824175824e-06,
      "loss": 0.0378,
      "step": 23150
    },
    {
      "epoch": 9.105180533751962,
      "grad_norm": 3.677114725112915,
      "learning_rate": 4.476059654631083e-06,
      "loss": 0.0381,
      "step": 23200
    },
    {
      "epoch": 9.12480376766091,
      "grad_norm": 3.3975608348846436,
      "learning_rate": 4.3779434850863424e-06,
      "loss": 0.0377,
      "step": 23250
    },
    {
      "epoch": 9.14442700156986,
      "grad_norm": 3.167957067489624,
      "learning_rate": 4.2798273155416015e-06,
      "loss": 0.038,
      "step": 23300
    },
    {
      "epoch": 9.164050235478808,
      "grad_norm": 3.9924070835113525,
      "learning_rate": 4.181711145996861e-06,
      "loss": 0.0379,
      "step": 23350
    },
    {
      "epoch": 9.183673469387756,
      "grad_norm": 2.6870150566101074,
      "learning_rate": 4.08359497645212e-06,
      "loss": 0.0378,
      "step": 23400
    },
    {
      "epoch": 9.203296703296703,
      "grad_norm": 5.246736526489258,
      "learning_rate": 3.985478806907379e-06,
      "loss": 0.0375,
      "step": 23450
    },
    {
      "epoch": 9.222919937205651,
      "grad_norm": 2.5441620349884033,
      "learning_rate": 3.887362637362638e-06,
      "loss": 0.0376,
      "step": 23500
    },
    {
      "epoch": 9.2425431711146,
      "grad_norm": 2.3757128715515137,
      "learning_rate": 3.789246467817897e-06,
      "loss": 0.0377,
      "step": 23550
    },
    {
      "epoch": 9.262166405023548,
      "grad_norm": 2.382079601287842,
      "learning_rate": 3.691130298273156e-06,
      "loss": 0.0378,
      "step": 23600
    },
    {
      "epoch": 9.281789638932496,
      "grad_norm": 1.895802617073059,
      "learning_rate": 3.593014128728415e-06,
      "loss": 0.0374,
      "step": 23650
    },
    {
      "epoch": 9.301412872841444,
      "grad_norm": 3.391740083694458,
      "learning_rate": 3.494897959183674e-06,
      "loss": 0.0374,
      "step": 23700
    },
    {
      "epoch": 9.321036106750393,
      "grad_norm": 3.9634017944335938,
      "learning_rate": 3.396781789638933e-06,
      "loss": 0.0378,
      "step": 23750
    },
    {
      "epoch": 9.340659340659341,
      "grad_norm": 3.376213312149048,
      "learning_rate": 3.2986656200941914e-06,
      "loss": 0.0375,
      "step": 23800
    },
    {
      "epoch": 9.36028257456829,
      "grad_norm": 4.717372894287109,
      "learning_rate": 3.2005494505494505e-06,
      "loss": 0.0377,
      "step": 23850
    },
    {
      "epoch": 9.379905808477236,
      "grad_norm": 2.9387359619140625,
      "learning_rate": 3.10243328100471e-06,
      "loss": 0.0375,
      "step": 23900
    },
    {
      "epoch": 9.399529042386185,
      "grad_norm": 2.7411646842956543,
      "learning_rate": 3.0043171114599686e-06,
      "loss": 0.0376,
      "step": 23950
    },
    {
      "epoch": 9.419152276295133,
      "grad_norm": 2.3034822940826416,
      "learning_rate": 2.9062009419152277e-06,
      "loss": 0.0371,
      "step": 24000
    },
    {
      "epoch": 9.438775510204081,
      "grad_norm": 2.02358078956604,
      "learning_rate": 2.808084772370487e-06,
      "loss": 0.0375,
      "step": 24050
    },
    {
      "epoch": 9.45839874411303,
      "grad_norm": 2.3690989017486572,
      "learning_rate": 2.709968602825746e-06,
      "loss": 0.037,
      "step": 24100
    },
    {
      "epoch": 9.478021978021978,
      "grad_norm": 3.631957530975342,
      "learning_rate": 2.611852433281005e-06,
      "loss": 0.0374,
      "step": 24150
    },
    {
      "epoch": 9.497645211930926,
      "grad_norm": 3.6301429271698,
      "learning_rate": 2.513736263736264e-06,
      "loss": 0.0376,
      "step": 24200
    },
    {
      "epoch": 9.517268445839875,
      "grad_norm": 3.424236536026001,
      "learning_rate": 2.415620094191523e-06,
      "loss": 0.0368,
      "step": 24250
    },
    {
      "epoch": 9.536891679748823,
      "grad_norm": 4.019447326660156,
      "learning_rate": 2.3175039246467817e-06,
      "loss": 0.0371,
      "step": 24300
    },
    {
      "epoch": 9.556514913657772,
      "grad_norm": 2.0341410636901855,
      "learning_rate": 2.219387755102041e-06,
      "loss": 0.0377,
      "step": 24350
    },
    {
      "epoch": 9.576138147566718,
      "grad_norm": 3.041138172149658,
      "learning_rate": 2.1212715855573e-06,
      "loss": 0.0371,
      "step": 24400
    },
    {
      "epoch": 9.595761381475667,
      "grad_norm": 2.2947778701782227,
      "learning_rate": 2.023155416012559e-06,
      "loss": 0.0376,
      "step": 24450
    },
    {
      "epoch": 9.615384615384615,
      "grad_norm": 1.646023154258728,
      "learning_rate": 1.925039246467818e-06,
      "loss": 0.0367,
      "step": 24500
    },
    {
      "epoch": 9.635007849293563,
      "grad_norm": 3.6993510723114014,
      "learning_rate": 1.8269230769230771e-06,
      "loss": 0.0371,
      "step": 24550
    },
    {
      "epoch": 9.654631083202512,
      "grad_norm": 2.573503017425537,
      "learning_rate": 1.7288069073783362e-06,
      "loss": 0.0371,
      "step": 24600
    },
    {
      "epoch": 9.67425431711146,
      "grad_norm": 3.544588088989258,
      "learning_rate": 1.6306907378335948e-06,
      "loss": 0.0367,
      "step": 24650
    },
    {
      "epoch": 9.693877551020408,
      "grad_norm": 3.849581480026245,
      "learning_rate": 1.5325745682888541e-06,
      "loss": 0.0368,
      "step": 24700
    },
    {
      "epoch": 9.713500784929357,
      "grad_norm": 3.508256673812866,
      "learning_rate": 1.434458398744113e-06,
      "loss": 0.0373,
      "step": 24750
    },
    {
      "epoch": 9.733124018838305,
      "grad_norm": 2.622730016708374,
      "learning_rate": 1.336342229199372e-06,
      "loss": 0.0373,
      "step": 24800
    },
    {
      "epoch": 9.752747252747252,
      "grad_norm": 2.381443500518799,
      "learning_rate": 1.2382260596546311e-06,
      "loss": 0.0372,
      "step": 24850
    },
    {
      "epoch": 9.7723704866562,
      "grad_norm": 2.956793785095215,
      "learning_rate": 1.14010989010989e-06,
      "loss": 0.0374,
      "step": 24900
    },
    {
      "epoch": 9.791993720565149,
      "grad_norm": 1.7385534048080444,
      "learning_rate": 1.041993720565149e-06,
      "loss": 0.0367,
      "step": 24950
    },
    {
      "epoch": 9.811616954474097,
      "grad_norm": 1.852442741394043,
      "learning_rate": 9.438775510204083e-07,
      "loss": 0.037,
      "step": 25000
    },
    {
      "epoch": 9.831240188383045,
      "grad_norm": 2.5808093547821045,
      "learning_rate": 8.457613814756671e-07,
      "loss": 0.0364,
      "step": 25050
    },
    {
      "epoch": 9.850863422291994,
      "grad_norm": 3.4102888107299805,
      "learning_rate": 7.476452119309262e-07,
      "loss": 0.0369,
      "step": 25100
    },
    {
      "epoch": 9.870486656200942,
      "grad_norm": 2.4007668495178223,
      "learning_rate": 6.495290423861853e-07,
      "loss": 0.0365,
      "step": 25150
    },
    {
      "epoch": 9.89010989010989,
      "grad_norm": 1.9161497354507446,
      "learning_rate": 5.514128728414443e-07,
      "loss": 0.0369,
      "step": 25200
    },
    {
      "epoch": 9.909733124018839,
      "grad_norm": 4.132075786590576,
      "learning_rate": 4.532967032967034e-07,
      "loss": 0.0368,
      "step": 25250
    },
    {
      "epoch": 9.929356357927787,
      "grad_norm": 2.7160418033599854,
      "learning_rate": 3.5518053375196235e-07,
      "loss": 0.037,
      "step": 25300
    },
    {
      "epoch": 9.948979591836736,
      "grad_norm": 2.4196691513061523,
      "learning_rate": 2.5706436420722137e-07,
      "loss": 0.0367,
      "step": 25350
    },
    {
      "epoch": 9.968602825745682,
      "grad_norm": 2.1881301403045654,
      "learning_rate": 1.589481946624804e-07,
      "loss": 0.0366,
      "step": 25400
    },
    {
      "epoch": 9.98822605965463,
      "grad_norm": 1.898012638092041,
      "learning_rate": 6.083202511773942e-08,
      "loss": 0.0365,
      "step": 25450
    },
    {
      "epoch": 10.0,
      "eval_runtime": 31.3384,
      "eval_samples_per_second": 650.257,
      "eval_steps_per_second": 20.327,
      "step": 25480
    },
    {
      "epoch": 10.007849293563579,
      "grad_norm": 5.757974624633789,
      "learning_rate": 2.49813579277865e-05,
      "loss": 0.0418,
      "step": 25500
    },
    {
      "epoch": 10.027472527472527,
      "grad_norm": 8.090387344360352,
      "learning_rate": 2.4932299843014127e-05,
      "loss": 0.0398,
      "step": 25550
    },
    {
      "epoch": 10.047095761381476,
      "grad_norm": 4.256542205810547,
      "learning_rate": 2.488324175824176e-05,
      "loss": 0.0396,
      "step": 25600
    },
    {
      "epoch": 10.066718995290424,
      "grad_norm": 4.0954179763793945,
      "learning_rate": 2.4834183673469388e-05,
      "loss": 0.0407,
      "step": 25650
    },
    {
      "epoch": 10.086342229199373,
      "grad_norm": 6.72625207901001,
      "learning_rate": 2.478512558869702e-05,
      "loss": 0.0399,
      "step": 25700
    },
    {
      "epoch": 10.105965463108321,
      "grad_norm": 4.453003406524658,
      "learning_rate": 2.473606750392465e-05,
      "loss": 0.0395,
      "step": 25750
    },
    {
      "epoch": 10.12558869701727,
      "grad_norm": 4.952942848205566,
      "learning_rate": 2.4687009419152276e-05,
      "loss": 0.04,
      "step": 25800
    },
    {
      "epoch": 10.145211930926216,
      "grad_norm": 4.254277229309082,
      "learning_rate": 2.4637951334379906e-05,
      "loss": 0.0394,
      "step": 25850
    },
    {
      "epoch": 10.164835164835164,
      "grad_norm": 4.593442916870117,
      "learning_rate": 2.4588893249607537e-05,
      "loss": 0.039,
      "step": 25900
    },
    {
      "epoch": 10.184458398744113,
      "grad_norm": 6.0503644943237305,
      "learning_rate": 2.4539835164835164e-05,
      "loss": 0.0388,
      "step": 25950
    },
    {
      "epoch": 10.204081632653061,
      "grad_norm": 3.6312685012817383,
      "learning_rate": 2.4490777080062797e-05,
      "loss": 0.0389,
      "step": 26000
    },
    {
      "epoch": 10.22370486656201,
      "grad_norm": 3.710120677947998,
      "learning_rate": 2.4441718995290424e-05,
      "loss": 0.0387,
      "step": 26050
    },
    {
      "epoch": 10.243328100470958,
      "grad_norm": 6.394252777099609,
      "learning_rate": 2.4392660910518055e-05,
      "loss": 0.039,
      "step": 26100
    },
    {
      "epoch": 10.262951334379906,
      "grad_norm": 5.15597677230835,
      "learning_rate": 2.4343602825745685e-05,
      "loss": 0.0388,
      "step": 26150
    },
    {
      "epoch": 10.282574568288855,
      "grad_norm": 4.67431640625,
      "learning_rate": 2.4294544740973312e-05,
      "loss": 0.0381,
      "step": 26200
    },
    {
      "epoch": 10.302197802197803,
      "grad_norm": 3.6843953132629395,
      "learning_rate": 2.4245486656200943e-05,
      "loss": 0.039,
      "step": 26250
    },
    {
      "epoch": 10.321821036106751,
      "grad_norm": 3.293212890625,
      "learning_rate": 2.4196428571428573e-05,
      "loss": 0.0382,
      "step": 26300
    },
    {
      "epoch": 10.341444270015698,
      "grad_norm": 5.114288330078125,
      "learning_rate": 2.41473704866562e-05,
      "loss": 0.0385,
      "step": 26350
    },
    {
      "epoch": 10.361067503924646,
      "grad_norm": 7.049236297607422,
      "learning_rate": 2.4098312401883834e-05,
      "loss": 0.0383,
      "step": 26400
    },
    {
      "epoch": 10.380690737833595,
      "grad_norm": 5.664878845214844,
      "learning_rate": 2.404925431711146e-05,
      "loss": 0.0386,
      "step": 26450
    },
    {
      "epoch": 10.400313971742543,
      "grad_norm": 4.7970733642578125,
      "learning_rate": 2.400019623233909e-05,
      "loss": 0.0384,
      "step": 26500
    },
    {
      "epoch": 10.419937205651491,
      "grad_norm": 6.636599063873291,
      "learning_rate": 2.395113814756672e-05,
      "loss": 0.0381,
      "step": 26550
    },
    {
      "epoch": 10.43956043956044,
      "grad_norm": 4.30007791519165,
      "learning_rate": 2.390208006279435e-05,
      "loss": 0.0382,
      "step": 26600
    },
    {
      "epoch": 10.459183673469388,
      "grad_norm": 6.566456317901611,
      "learning_rate": 2.385302197802198e-05,
      "loss": 0.0388,
      "step": 26650
    },
    {
      "epoch": 10.478806907378337,
      "grad_norm": 4.581142902374268,
      "learning_rate": 2.380396389324961e-05,
      "loss": 0.0379,
      "step": 26700
    },
    {
      "epoch": 10.498430141287285,
      "grad_norm": 6.4189453125,
      "learning_rate": 2.3754905808477236e-05,
      "loss": 0.0381,
      "step": 26750
    },
    {
      "epoch": 10.518053375196232,
      "grad_norm": 4.504387855529785,
      "learning_rate": 2.370584772370487e-05,
      "loss": 0.0383,
      "step": 26800
    },
    {
      "epoch": 10.53767660910518,
      "grad_norm": 4.8061347007751465,
      "learning_rate": 2.3656789638932497e-05,
      "loss": 0.0377,
      "step": 26850
    },
    {
      "epoch": 10.557299843014128,
      "grad_norm": 5.513097763061523,
      "learning_rate": 2.3607731554160127e-05,
      "loss": 0.0376,
      "step": 26900
    },
    {
      "epoch": 10.576923076923077,
      "grad_norm": 4.129086971282959,
      "learning_rate": 2.3558673469387758e-05,
      "loss": 0.0377,
      "step": 26950
    },
    {
      "epoch": 10.596546310832025,
      "grad_norm": 3.9019811153411865,
      "learning_rate": 2.3509615384615385e-05,
      "loss": 0.0371,
      "step": 27000
    },
    {
      "epoch": 10.616169544740973,
      "grad_norm": 4.242355823516846,
      "learning_rate": 2.3460557299843015e-05,
      "loss": 0.0362,
      "step": 27050
    },
    {
      "epoch": 10.635792778649922,
      "grad_norm": 4.57944393157959,
      "learning_rate": 2.3411499215070646e-05,
      "loss": 0.0374,
      "step": 27100
    },
    {
      "epoch": 10.65541601255887,
      "grad_norm": 7.781904220581055,
      "learning_rate": 2.3362441130298273e-05,
      "loss": 0.0376,
      "step": 27150
    },
    {
      "epoch": 10.675039246467819,
      "grad_norm": 5.183505058288574,
      "learning_rate": 2.3313383045525906e-05,
      "loss": 0.037,
      "step": 27200
    },
    {
      "epoch": 10.694662480376767,
      "grad_norm": 5.264232635498047,
      "learning_rate": 2.3264324960753533e-05,
      "loss": 0.0378,
      "step": 27250
    },
    {
      "epoch": 10.714285714285714,
      "grad_norm": 4.381650924682617,
      "learning_rate": 2.3215266875981164e-05,
      "loss": 0.0366,
      "step": 27300
    },
    {
      "epoch": 10.733908948194662,
      "grad_norm": 4.680823802947998,
      "learning_rate": 2.3166208791208794e-05,
      "loss": 0.0367,
      "step": 27350
    },
    {
      "epoch": 10.75353218210361,
      "grad_norm": 5.508571147918701,
      "learning_rate": 2.311715070643642e-05,
      "loss": 0.0366,
      "step": 27400
    },
    {
      "epoch": 10.773155416012559,
      "grad_norm": 3.769892930984497,
      "learning_rate": 2.306809262166405e-05,
      "loss": 0.0367,
      "step": 27450
    },
    {
      "epoch": 10.792778649921507,
      "grad_norm": 4.8036675453186035,
      "learning_rate": 2.3019034536891682e-05,
      "loss": 0.0372,
      "step": 27500
    },
    {
      "epoch": 10.812401883830455,
      "grad_norm": 4.719215393066406,
      "learning_rate": 2.296997645211931e-05,
      "loss": 0.0365,
      "step": 27550
    },
    {
      "epoch": 10.832025117739404,
      "grad_norm": 3.2562949657440186,
      "learning_rate": 2.292091836734694e-05,
      "loss": 0.0362,
      "step": 27600
    },
    {
      "epoch": 10.851648351648352,
      "grad_norm": 6.35847806930542,
      "learning_rate": 2.287186028257457e-05,
      "loss": 0.036,
      "step": 27650
    },
    {
      "epoch": 10.8712715855573,
      "grad_norm": 4.430943965911865,
      "learning_rate": 2.28228021978022e-05,
      "loss": 0.0363,
      "step": 27700
    },
    {
      "epoch": 10.890894819466247,
      "grad_norm": 2.2020840644836426,
      "learning_rate": 2.277374411302983e-05,
      "loss": 0.0358,
      "step": 27750
    },
    {
      "epoch": 10.910518053375196,
      "grad_norm": 6.295289516448975,
      "learning_rate": 2.2724686028257457e-05,
      "loss": 0.0363,
      "step": 27800
    },
    {
      "epoch": 10.930141287284144,
      "grad_norm": 3.6311168670654297,
      "learning_rate": 2.2675627943485088e-05,
      "loss": 0.0362,
      "step": 27850
    },
    {
      "epoch": 10.949764521193092,
      "grad_norm": 5.845851421356201,
      "learning_rate": 2.2626569858712718e-05,
      "loss": 0.0365,
      "step": 27900
    },
    {
      "epoch": 10.96938775510204,
      "grad_norm": 5.908734321594238,
      "learning_rate": 2.2577511773940345e-05,
      "loss": 0.0358,
      "step": 27950
    },
    {
      "epoch": 10.989010989010989,
      "grad_norm": 6.599799633026123,
      "learning_rate": 2.2528453689167976e-05,
      "loss": 0.0362,
      "step": 28000
    },
    {
      "epoch": 11.0,
      "eval_runtime": 30.869,
      "eval_samples_per_second": 660.144,
      "eval_steps_per_second": 20.636,
      "step": 28028
    }
  ],
  "logging_steps": 50,
  "max_steps": 50960,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.460203541102592e+16,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
