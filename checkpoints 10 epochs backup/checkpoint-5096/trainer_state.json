{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 5096,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.019623233908948195,
      "grad_norm": 0.30839964747428894,
      "learning_rate": 4.9903846153846154e-05,
      "loss": 0.6412,
      "step": 50
    },
    {
      "epoch": 0.03924646781789639,
      "grad_norm": 0.2794131934642792,
      "learning_rate": 4.9805729984301415e-05,
      "loss": 0.4855,
      "step": 100
    },
    {
      "epoch": 0.05886970172684458,
      "grad_norm": 2.256641149520874,
      "learning_rate": 4.9707613814756676e-05,
      "loss": 0.367,
      "step": 150
    },
    {
      "epoch": 0.07849293563579278,
      "grad_norm": 0.9094319343566895,
      "learning_rate": 4.960949764521193e-05,
      "loss": 0.2945,
      "step": 200
    },
    {
      "epoch": 0.09811616954474098,
      "grad_norm": 0.811332106590271,
      "learning_rate": 4.951138147566719e-05,
      "loss": 0.2667,
      "step": 250
    },
    {
      "epoch": 0.11773940345368916,
      "grad_norm": 0.7112467288970947,
      "learning_rate": 4.941326530612245e-05,
      "loss": 0.252,
      "step": 300
    },
    {
      "epoch": 0.13736263736263737,
      "grad_norm": 0.8579742908477783,
      "learning_rate": 4.931514913657771e-05,
      "loss": 0.2437,
      "step": 350
    },
    {
      "epoch": 0.15698587127158556,
      "grad_norm": 0.4823269248008728,
      "learning_rate": 4.9217032967032966e-05,
      "loss": 0.235,
      "step": 400
    },
    {
      "epoch": 0.17660910518053374,
      "grad_norm": 1.1497149467468262,
      "learning_rate": 4.911891679748823e-05,
      "loss": 0.2338,
      "step": 450
    },
    {
      "epoch": 0.19623233908948196,
      "grad_norm": 0.7090773582458496,
      "learning_rate": 4.902080062794349e-05,
      "loss": 0.2303,
      "step": 500
    },
    {
      "epoch": 0.21585557299843014,
      "grad_norm": 0.9524086117744446,
      "learning_rate": 4.892268445839875e-05,
      "loss": 0.2276,
      "step": 550
    },
    {
      "epoch": 0.23547880690737832,
      "grad_norm": 1.5349451303482056,
      "learning_rate": 4.8824568288854e-05,
      "loss": 0.2247,
      "step": 600
    },
    {
      "epoch": 0.25510204081632654,
      "grad_norm": 0.48404359817504883,
      "learning_rate": 4.872645211930926e-05,
      "loss": 0.2254,
      "step": 650
    },
    {
      "epoch": 0.27472527472527475,
      "grad_norm": 1.1404423713684082,
      "learning_rate": 4.8628335949764524e-05,
      "loss": 0.2249,
      "step": 700
    },
    {
      "epoch": 0.2943485086342229,
      "grad_norm": 1.353710651397705,
      "learning_rate": 4.8530219780219785e-05,
      "loss": 0.2217,
      "step": 750
    },
    {
      "epoch": 0.3139717425431711,
      "grad_norm": 0.567766547203064,
      "learning_rate": 4.843210361067504e-05,
      "loss": 0.2262,
      "step": 800
    },
    {
      "epoch": 0.33359497645211933,
      "grad_norm": 0.8271063566207886,
      "learning_rate": 4.83339874411303e-05,
      "loss": 0.2191,
      "step": 850
    },
    {
      "epoch": 0.3532182103610675,
      "grad_norm": 0.6242493391036987,
      "learning_rate": 4.823587127158556e-05,
      "loss": 0.2193,
      "step": 900
    },
    {
      "epoch": 0.3728414442700157,
      "grad_norm": 1.1799074411392212,
      "learning_rate": 4.813775510204082e-05,
      "loss": 0.2163,
      "step": 950
    },
    {
      "epoch": 0.3924646781789639,
      "grad_norm": 0.6452319025993347,
      "learning_rate": 4.8039638932496075e-05,
      "loss": 0.2166,
      "step": 1000
    },
    {
      "epoch": 0.41208791208791207,
      "grad_norm": 0.8252454996109009,
      "learning_rate": 4.7941522762951336e-05,
      "loss": 0.2166,
      "step": 1050
    },
    {
      "epoch": 0.4317111459968603,
      "grad_norm": 0.8099313378334045,
      "learning_rate": 4.78434065934066e-05,
      "loss": 0.213,
      "step": 1100
    },
    {
      "epoch": 0.4513343799058085,
      "grad_norm": 0.8590015769004822,
      "learning_rate": 4.774529042386186e-05,
      "loss": 0.2156,
      "step": 1150
    },
    {
      "epoch": 0.47095761381475665,
      "grad_norm": 0.7966881990432739,
      "learning_rate": 4.764717425431711e-05,
      "loss": 0.211,
      "step": 1200
    },
    {
      "epoch": 0.49058084772370486,
      "grad_norm": 0.5888208150863647,
      "learning_rate": 4.754905808477237e-05,
      "loss": 0.2124,
      "step": 1250
    },
    {
      "epoch": 0.5102040816326531,
      "grad_norm": 1.048002004623413,
      "learning_rate": 4.745094191522763e-05,
      "loss": 0.2113,
      "step": 1300
    },
    {
      "epoch": 0.5298273155416012,
      "grad_norm": 1.1078420877456665,
      "learning_rate": 4.735282574568289e-05,
      "loss": 0.2112,
      "step": 1350
    },
    {
      "epoch": 0.5494505494505495,
      "grad_norm": 0.7269852757453918,
      "learning_rate": 4.725470957613815e-05,
      "loss": 0.2121,
      "step": 1400
    },
    {
      "epoch": 0.5690737833594977,
      "grad_norm": 0.6617816686630249,
      "learning_rate": 4.715659340659341e-05,
      "loss": 0.2063,
      "step": 1450
    },
    {
      "epoch": 0.5886970172684458,
      "grad_norm": 0.9398244619369507,
      "learning_rate": 4.705847723704867e-05,
      "loss": 0.2082,
      "step": 1500
    },
    {
      "epoch": 0.6083202511773941,
      "grad_norm": 0.5138371586799622,
      "learning_rate": 4.696036106750393e-05,
      "loss": 0.2033,
      "step": 1550
    },
    {
      "epoch": 0.6279434850863422,
      "grad_norm": 1.1170330047607422,
      "learning_rate": 4.6862244897959184e-05,
      "loss": 0.203,
      "step": 1600
    },
    {
      "epoch": 0.6475667189952904,
      "grad_norm": 0.8364686965942383,
      "learning_rate": 4.6764128728414445e-05,
      "loss": 0.1998,
      "step": 1650
    },
    {
      "epoch": 0.6671899529042387,
      "grad_norm": 0.4572080373764038,
      "learning_rate": 4.6666012558869706e-05,
      "loss": 0.2011,
      "step": 1700
    },
    {
      "epoch": 0.6868131868131868,
      "grad_norm": 0.6296447515487671,
      "learning_rate": 4.656789638932496e-05,
      "loss": 0.1987,
      "step": 1750
    },
    {
      "epoch": 0.706436420722135,
      "grad_norm": 1.5071191787719727,
      "learning_rate": 4.646978021978022e-05,
      "loss": 0.1976,
      "step": 1800
    },
    {
      "epoch": 0.7260596546310832,
      "grad_norm": 1.3817378282546997,
      "learning_rate": 4.637166405023548e-05,
      "loss": 0.1973,
      "step": 1850
    },
    {
      "epoch": 0.7456828885400314,
      "grad_norm": 1.260256052017212,
      "learning_rate": 4.6273547880690735e-05,
      "loss": 0.1947,
      "step": 1900
    },
    {
      "epoch": 0.7653061224489796,
      "grad_norm": 1.3558027744293213,
      "learning_rate": 4.6175431711146e-05,
      "loss": 0.1944,
      "step": 1950
    },
    {
      "epoch": 0.7849293563579278,
      "grad_norm": 1.3628939390182495,
      "learning_rate": 4.607731554160126e-05,
      "loss": 0.1923,
      "step": 2000
    },
    {
      "epoch": 0.804552590266876,
      "grad_norm": 1.451006531715393,
      "learning_rate": 4.597919937205652e-05,
      "loss": 0.1889,
      "step": 2050
    },
    {
      "epoch": 0.8241758241758241,
      "grad_norm": 1.4819344282150269,
      "learning_rate": 4.588108320251178e-05,
      "loss": 0.1862,
      "step": 2100
    },
    {
      "epoch": 0.8437990580847724,
      "grad_norm": 1.1625503301620483,
      "learning_rate": 4.578296703296703e-05,
      "loss": 0.1858,
      "step": 2150
    },
    {
      "epoch": 0.8634222919937206,
      "grad_norm": 1.5611393451690674,
      "learning_rate": 4.568485086342229e-05,
      "loss": 0.1839,
      "step": 2200
    },
    {
      "epoch": 0.8830455259026687,
      "grad_norm": 1.2459888458251953,
      "learning_rate": 4.5586734693877554e-05,
      "loss": 0.1812,
      "step": 2250
    },
    {
      "epoch": 0.902668759811617,
      "grad_norm": 1.4682022333145142,
      "learning_rate": 4.548861852433281e-05,
      "loss": 0.1828,
      "step": 2300
    },
    {
      "epoch": 0.9222919937205651,
      "grad_norm": 1.8903566598892212,
      "learning_rate": 4.5390502354788075e-05,
      "loss": 0.1815,
      "step": 2350
    },
    {
      "epoch": 0.9419152276295133,
      "grad_norm": 2.0343968868255615,
      "learning_rate": 4.529238618524333e-05,
      "loss": 0.18,
      "step": 2400
    },
    {
      "epoch": 0.9615384615384616,
      "grad_norm": 3.104841947555542,
      "learning_rate": 4.519427001569858e-05,
      "loss": 0.1797,
      "step": 2450
    },
    {
      "epoch": 0.9811616954474097,
      "grad_norm": 0.941974401473999,
      "learning_rate": 4.509615384615385e-05,
      "loss": 0.1752,
      "step": 2500
    },
    {
      "epoch": 1.0,
      "eval_runtime": 30.9381,
      "eval_samples_per_second": 658.671,
      "eval_steps_per_second": 20.59,
      "step": 2548
    },
    {
      "epoch": 1.000784929356358,
      "grad_norm": 1.9551867246627808,
      "learning_rate": 4.4998037676609105e-05,
      "loss": 0.1783,
      "step": 2550
    },
    {
      "epoch": 1.0204081632653061,
      "grad_norm": 2.535970687866211,
      "learning_rate": 4.4899921507064366e-05,
      "loss": 0.1746,
      "step": 2600
    },
    {
      "epoch": 1.0400313971742543,
      "grad_norm": 5.567418098449707,
      "learning_rate": 4.4801805337519626e-05,
      "loss": 0.1728,
      "step": 2650
    },
    {
      "epoch": 1.0596546310832025,
      "grad_norm": 2.597290515899658,
      "learning_rate": 4.470368916797488e-05,
      "loss": 0.1694,
      "step": 2700
    },
    {
      "epoch": 1.0792778649921506,
      "grad_norm": 1.5226540565490723,
      "learning_rate": 4.460557299843015e-05,
      "loss": 0.1737,
      "step": 2750
    },
    {
      "epoch": 1.098901098901099,
      "grad_norm": 2.55260968208313,
      "learning_rate": 4.45074568288854e-05,
      "loss": 0.1695,
      "step": 2800
    },
    {
      "epoch": 1.1185243328100472,
      "grad_norm": 3.401707887649536,
      "learning_rate": 4.4409340659340656e-05,
      "loss": 0.1685,
      "step": 2850
    },
    {
      "epoch": 1.1381475667189953,
      "grad_norm": 2.816251039505005,
      "learning_rate": 4.4311224489795923e-05,
      "loss": 0.1708,
      "step": 2900
    },
    {
      "epoch": 1.1577708006279435,
      "grad_norm": 3.3615949153900146,
      "learning_rate": 4.421310832025118e-05,
      "loss": 0.1668,
      "step": 2950
    },
    {
      "epoch": 1.1773940345368916,
      "grad_norm": 2.1576547622680664,
      "learning_rate": 4.411499215070644e-05,
      "loss": 0.1666,
      "step": 3000
    },
    {
      "epoch": 1.19701726844584,
      "grad_norm": 1.5313994884490967,
      "learning_rate": 4.40168759811617e-05,
      "loss": 0.1653,
      "step": 3050
    },
    {
      "epoch": 1.2166405023547882,
      "grad_norm": 3.8457231521606445,
      "learning_rate": 4.391875981161695e-05,
      "loss": 0.1649,
      "step": 3100
    },
    {
      "epoch": 1.2362637362637363,
      "grad_norm": 1.9840260744094849,
      "learning_rate": 4.382064364207222e-05,
      "loss": 0.1622,
      "step": 3150
    },
    {
      "epoch": 1.2558869701726845,
      "grad_norm": 4.362919330596924,
      "learning_rate": 4.3722527472527474e-05,
      "loss": 0.1625,
      "step": 3200
    },
    {
      "epoch": 1.2755102040816326,
      "grad_norm": 3.335237741470337,
      "learning_rate": 4.362441130298273e-05,
      "loss": 0.1621,
      "step": 3250
    },
    {
      "epoch": 1.2951334379905808,
      "grad_norm": 5.26850700378418,
      "learning_rate": 4.3526295133437996e-05,
      "loss": 0.1624,
      "step": 3300
    },
    {
      "epoch": 1.314756671899529,
      "grad_norm": 4.735275745391846,
      "learning_rate": 4.342817896389325e-05,
      "loss": 0.1616,
      "step": 3350
    },
    {
      "epoch": 1.3343799058084773,
      "grad_norm": 2.325209140777588,
      "learning_rate": 4.333006279434851e-05,
      "loss": 0.1599,
      "step": 3400
    },
    {
      "epoch": 1.3540031397174255,
      "grad_norm": 3.258694887161255,
      "learning_rate": 4.323194662480377e-05,
      "loss": 0.1575,
      "step": 3450
    },
    {
      "epoch": 1.3736263736263736,
      "grad_norm": 3.6141488552093506,
      "learning_rate": 4.3133830455259026e-05,
      "loss": 0.1583,
      "step": 3500
    },
    {
      "epoch": 1.3932496075353218,
      "grad_norm": 3.8222134113311768,
      "learning_rate": 4.303571428571429e-05,
      "loss": 0.1561,
      "step": 3550
    },
    {
      "epoch": 1.41287284144427,
      "grad_norm": 3.1434764862060547,
      "learning_rate": 4.293759811616955e-05,
      "loss": 0.1575,
      "step": 3600
    },
    {
      "epoch": 1.4324960753532183,
      "grad_norm": 2.6277294158935547,
      "learning_rate": 4.28394819466248e-05,
      "loss": 0.156,
      "step": 3650
    },
    {
      "epoch": 1.4521193092621665,
      "grad_norm": 7.460547924041748,
      "learning_rate": 4.274136577708007e-05,
      "loss": 0.1559,
      "step": 3700
    },
    {
      "epoch": 1.4717425431711146,
      "grad_norm": 3.8251636028289795,
      "learning_rate": 4.264324960753532e-05,
      "loss": 0.1551,
      "step": 3750
    },
    {
      "epoch": 1.4913657770800628,
      "grad_norm": 5.55992317199707,
      "learning_rate": 4.254513343799058e-05,
      "loss": 0.1539,
      "step": 3800
    },
    {
      "epoch": 1.510989010989011,
      "grad_norm": 4.436182975769043,
      "learning_rate": 4.2447017268445844e-05,
      "loss": 0.1537,
      "step": 3850
    },
    {
      "epoch": 1.5306122448979593,
      "grad_norm": 5.019519329071045,
      "learning_rate": 4.23489010989011e-05,
      "loss": 0.1553,
      "step": 3900
    },
    {
      "epoch": 1.5502354788069073,
      "grad_norm": 4.0342936515808105,
      "learning_rate": 4.225078492935636e-05,
      "loss": 0.1524,
      "step": 3950
    },
    {
      "epoch": 1.5698587127158556,
      "grad_norm": 3.145026683807373,
      "learning_rate": 4.215266875981162e-05,
      "loss": 0.1512,
      "step": 4000
    },
    {
      "epoch": 1.5894819466248038,
      "grad_norm": 8.127691268920898,
      "learning_rate": 4.2054552590266874e-05,
      "loss": 0.1486,
      "step": 4050
    },
    {
      "epoch": 1.609105180533752,
      "grad_norm": 4.4838385581970215,
      "learning_rate": 4.195643642072214e-05,
      "loss": 0.1519,
      "step": 4100
    },
    {
      "epoch": 1.6287284144427001,
      "grad_norm": 4.023062705993652,
      "learning_rate": 4.1858320251177395e-05,
      "loss": 0.1501,
      "step": 4150
    },
    {
      "epoch": 1.6483516483516483,
      "grad_norm": 2.3843178749084473,
      "learning_rate": 4.1760204081632656e-05,
      "loss": 0.1463,
      "step": 4200
    },
    {
      "epoch": 1.6679748822605966,
      "grad_norm": 5.4677205085754395,
      "learning_rate": 4.166208791208792e-05,
      "loss": 0.1486,
      "step": 4250
    },
    {
      "epoch": 1.6875981161695446,
      "grad_norm": 3.162881851196289,
      "learning_rate": 4.156397174254317e-05,
      "loss": 0.1471,
      "step": 4300
    },
    {
      "epoch": 1.707221350078493,
      "grad_norm": 4.266803741455078,
      "learning_rate": 4.146585557299843e-05,
      "loss": 0.1486,
      "step": 4350
    },
    {
      "epoch": 1.7268445839874411,
      "grad_norm": 3.9153130054473877,
      "learning_rate": 4.136773940345369e-05,
      "loss": 0.148,
      "step": 4400
    },
    {
      "epoch": 1.7464678178963893,
      "grad_norm": 4.988833427429199,
      "learning_rate": 4.1269623233908946e-05,
      "loss": 0.1453,
      "step": 4450
    },
    {
      "epoch": 1.7660910518053377,
      "grad_norm": 4.468367099761963,
      "learning_rate": 4.117150706436421e-05,
      "loss": 0.1433,
      "step": 4500
    },
    {
      "epoch": 1.7857142857142856,
      "grad_norm": 3.586076021194458,
      "learning_rate": 4.107339089481947e-05,
      "loss": 0.1447,
      "step": 4550
    },
    {
      "epoch": 1.805337519623234,
      "grad_norm": 6.366526126861572,
      "learning_rate": 4.097527472527473e-05,
      "loss": 0.1417,
      "step": 4600
    },
    {
      "epoch": 1.8249607535321821,
      "grad_norm": 3.3398170471191406,
      "learning_rate": 4.087715855572999e-05,
      "loss": 0.143,
      "step": 4650
    },
    {
      "epoch": 1.8445839874411303,
      "grad_norm": 4.038153648376465,
      "learning_rate": 4.077904238618524e-05,
      "loss": 0.1394,
      "step": 4700
    },
    {
      "epoch": 1.8642072213500787,
      "grad_norm": 6.498599052429199,
      "learning_rate": 4.0680926216640504e-05,
      "loss": 0.1384,
      "step": 4750
    },
    {
      "epoch": 1.8838304552590266,
      "grad_norm": 6.430575847625732,
      "learning_rate": 4.0582810047095765e-05,
      "loss": 0.1387,
      "step": 4800
    },
    {
      "epoch": 1.903453689167975,
      "grad_norm": 5.406408786773682,
      "learning_rate": 4.048469387755102e-05,
      "loss": 0.1398,
      "step": 4850
    },
    {
      "epoch": 1.9230769230769231,
      "grad_norm": 4.788869380950928,
      "learning_rate": 4.038657770800628e-05,
      "loss": 0.1382,
      "step": 4900
    },
    {
      "epoch": 1.9427001569858713,
      "grad_norm": 4.118043422698975,
      "learning_rate": 4.028846153846154e-05,
      "loss": 0.1352,
      "step": 4950
    },
    {
      "epoch": 1.9623233908948194,
      "grad_norm": 3.4045255184173584,
      "learning_rate": 4.01903453689168e-05,
      "loss": 0.136,
      "step": 5000
    },
    {
      "epoch": 1.9819466248037676,
      "grad_norm": 5.152231693267822,
      "learning_rate": 4.009222919937206e-05,
      "loss": 0.1373,
      "step": 5050
    },
    {
      "epoch": 2.0,
      "eval_runtime": 30.9507,
      "eval_samples_per_second": 658.401,
      "eval_steps_per_second": 20.581,
      "step": 5096
    }
  ],
  "logging_steps": 50,
  "max_steps": 25480,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2654915529277440.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
